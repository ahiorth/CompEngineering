.. !split

.. _ch:ode:

Ordinary differential equations          (1)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

0D models
=========
By 0D models we mean models that are only dependent on one variable, usually time. These models are often called "lumped parameter models", because they ignore spatial dependency and the parameters in the model are adjusted to match experimental data. In many cases it is more important to predict how a system evolves in time, than the spatial dependency. A very recent example is the spread of infectious deceases, like Covid-19, where the evolution of total number of infected people might be the most important and not where the infection happens. 

Ordinary differential equations          (2)
============================================

Physical systems evolves in space and time, and very often they are described by a ordinary differential equations (ODE) and/or
partial differential equations (PDE). The difference between an ODE and a PDE is that an ODE only describes 
the changes in one spatial dimension *or* time, whereas a PDE describes a system that evolves in the :math:`x-`, :math:`y-`, :math:`z-` dimension 
and/or in time. In the following we will spend a significant
amount of time to explore one of the simplest algorithm, Eulers method.
Sometimes this is exactly the algorithm you would like to use, but with very 
little extra effort much more sophisticated algorithms can easily be implemented, such as the Runge-Kutta fourth order method.
However, all these algorithms, will at some point run into the same
kind of troubles if used reckless. Thus we will use the Eulers method as a playground,
investigate when the algorithm run into trouble and
suggests ways to fix it, these approaches can easily be extended to the higher order methods. Most of the other algorithms boils down to the same idea of extrapolating
a function using derivatives multiplied with a small step size.  

A simple model for fluid flow
=============================

.. index:: continuous stirred tank reactor (CSTR)

Let us consider a simple example from chemical engineering, a continuous stirred tank reactor (CSTR), see figure :ref:`fig:ode:cstr`. 
The flow is incompressible (:math:`q_\text{out}=q_\text{in}`), a fluid is entering
on the top and exiting at the bottom, the tank has a fixed volume :math:`V`. Assume that the tank is filled with saltwater, and that freshwater is pumped into it, how much time does it 
take before :math:`90\%` of the saltwater is replaced with freshwater? The tank is *well mixed*, illustrated with the propeller, this means that at every time the 
concentration is uniform in the tank, i.e. that :math:`C(t)=C_\text{out}(t)`.  

.. _fig:ode:cstr:

.. figure:: fig-ode/cstr.png
   :width: 800

   A continuous stirred tank model, :math:`C(t)=C_\text{out}(t)`, and :math:`q_\text{out}=q_\text{in}`

The concentration :math:`C` is measured in gram of salt per liter water, and the flow rate :math:`q` is liter of water per day. The model for the salt balance in this system can be described in words by:

.. math::
        
        [\text{accumulation of salt}] = [\text{salt into the system}] - [\text{salt out of the system}]\nonumber
        

.. _Eq:eq:ode:mbal:

.. math::

    \tag{256}
    + [\text{generation of salt}].\
        

In our case there are no generation of salt within the system so this term is zero. The flow of salt into the system during a time :math:`\Delta t` is: 
:math:`q_\text{in}(t)\cdot C_\text{in}(t)\cdot \Delta t=q(t)\cdot C_\text{in}(t)\cdot \Delta t`, 
the flow of salt out of the system is: :math:`q_\text{out}(t)\cdot C_\text{out}(t)\cdot \Delta t=q(t)\cdot C(t)\cdot \Delta t`, and the accumulation during a time step is:
:math:`C(t+\Delta t)\cdot V - C(t)\cdot V`, hence:

.. _Eq:eq:ode:cstr1:

.. math::

    \tag{257}
    C(t+\Delta t)\cdot V - C(t)\cdot V = q(t)\cdot C_\text{in}(t)\cdot \Delta t - q(t)\cdot C(t)\cdot \Delta t.\
        

Note that it is not a priori apparent, which time the concentrations and flow rates on the right hand side should be evaluated at, 
we could have chosen to evaluate them at :math:`t+\Delta t`, or at any time :math:`t\in [t,t+\Delta t]`. We will return to this point later in this chapter. Dividing by :math:`\Delta t`, and taking the limit
:math:`\Delta t\to 0`, we can write equation :ref:`(257) <Eq:eq:ode:cstr1>` as:

.. _Eq:eq:ode:cstr2:

.. math::

    \tag{258}
    V\frac{dC(t)}{dt} = q(t)\left[C_\text{in}(t) - C(t)\right].\
        

Seawater contains about 35 gram salt/liter fluid, if we assume that the fresh water contains no salt, we have the boundary conditions
:math:`C_\text{in}(t)=0`, $C(0)=$35gram/l. The equation :ref:`(258) <Eq:eq:ode:cstr2>` the reduces to:

.. _Eq:eq:ode:cstr3:

.. math::

    \tag{259}
    V\frac{dC(t)}{dt} = -qC(t),\
        

this equation can easily be solved, by dividing by :math:`C`, multiplying by :math:`dt` and integrating:

.. math::
        
        V\int_{C_0}^C\frac{dC}{C} = -q\int_0^tdt,\nonumber
        

.. _Eq:eq:ode:sol:

.. math::

    \tag{260}
    C(t)=C_0e^{-t/\tau},\text{ where } \tau\equiv \frac{V}{q}.\
        

This equation can be inverted to give :math:`t=-\tau\ln[C(t)/C]`. If we assume that the volume of the tank is 1m$^3$=1000liters, 
and that the flow rate is 1 liter/min, we find that $\tau$=1000min=0.69days and that it takes about $-0.69\ln0.9\simeq1.6$days to reduce the concentration
by 90$\%$ to 3.5 gram/liter.     


.. admonition:: The CSTR

   You might think that the CSTR is a very simple model, and it is, but this type of model is the basic building blocks in chemical engineering.
   By putting CSTR tanks in series and/or connecting them with pipes, the efficiency of manufacturing various type of chemicals
   can be investigated. Although the CSTR is an idealized model for the part of a chemical factory, it is actually a *very good* model 
   for fluid flow in a porous media. By connecting CSTR tanks in series, one can model how chemical tracers propagate in the subsurface. 
   The physical reason for this is that dispersion in porous media will play the role of the propellers and mix the concentration
   uniformly.




Euler's method
==============

.. index:: Eulers method

If the system gets slightly more complicated, e.g several tanks in series with a varying flow rate or if salt was generated in the tank, there is a
good chance that we have to solve the equations numerically to obtain a solution.
Actually, we have already developed a numerical algorithm to solve equation :ref:`(258) <Eq:eq:ode:cstr2>`, 
before we arrived at equation :ref:`(258) <Eq:eq:ode:cstr2>` in equation :ref:`(257) <Eq:eq:ode:cstr1>`. This is a special case of Eulers method, which is basically to 
replace the derivative in equation :ref:`(258) <Eq:eq:ode:cstr2>`, with :math:`(C(t+\Delta t)-C(t))/\Delta t`. By rewriting equation :ref:`(257) <Eq:eq:ode:cstr1>`, so that we
keep everything related to the new time step, :math:`t+\Delta t`, on one side, we get:

.. _Eq:eq:ode:eu0:

.. math::

    \tag{261}
    VC(t+\Delta t) = VC(t) + qC_\text{in}(t) - qC(t),\
        

.. _Eq:eq:ode:eu1:

.. math::

    \tag{262}
    C(t+\Delta t) = C(t) + \frac{\Delta t}{\tau}\left[C_\text{in}(t) - C(t)\right]\,
        

we introduce the short hand notation: :math:`C(t)=C_n`, and :math:`C(t+\Delta t)=C_{n+1}`, hence the algorithm can be written more compact as:

.. _Eq:eq:ode:eu2:

.. math::

    \tag{263}
    C_{n+1} = \left(1-\frac{\Delta t}{\tau}\right)C_n + \frac{\Delta t}{\tau}C_{\text{in},n}\,
        

In the script below, we have implemented equation :ref:`(263) <Eq:eq:ode:eu2>`.

.. code-block:: python

    def analytical(x):
        return np.exp(-x)
    
    def euler_step(c_old, c_in, tau_inv,dt):
        fact=dt*tau_inv
        return (1-fact)*c_old+fact*c_in
    
    def ode_solv(c_into,c_init,t_final,vol,q,dt):
        f=[];t=[]
        tau_inv = q/vol
        c_in    = c_into #freshwater into tank
        c_old   = c_init #seawater present 
        ti=0.
        while(ti <= t_final):
            t.append(ti); f.append(c_old)
            c_new = euler_step(c_old,c_in,tau_inv,dt)     
            c_old = c_new
            ti   += dt
        return t,f

.. _fig:ode:euler:

.. figure:: fig-ode/euler.png
   :width: 800

   The concentration in the tank for different step size :math:`\Delta t`

In figure :ref:`fig:ode:euler` the result of the implementation is shown for different values of :math:`\Delta t`.
Clearly we see that the results are dependent on the step size, as the step increases the numerical solution deviates from the analytical solution. At some point the 
numerical algorithm fails completely, and produces results that have no meaning. 

Error analysis - Euler's method
-------------------------------

.. index::
   single: Eulers method, error analysis

There are two obvious questions:
1. When does the algorithm produce unphysical results?  

2. What is an appropriate step size? 

Let us consider the first question, clearly when the concentrations gets negative the solution is unphysical. From equation :ref:`(263) <Eq:eq:ode:eu2>`, 
we see that when :math:`\Delta t/\tau > 1`, the concentration 
become negative. For this specific case (the CSTR), there is a clear physical interpretation of this condition. Inserting :math:`\tau=V/q`, we can rewrite
the condition :math:`\Delta t/\tau <1` as :math:`q\Delta t < V`. The volume into the tank during one time step is: :math:`q\Delta t`, which means that
whenever we *flush more than one tank volume through the tank during one time step, the algorithm fails*.
When this happens the new concentration in the tank cannot be predicted from the old one. This makes sense, because we could have switched to a
new solution (e.g. seawater) during that time step, then the new solution does not have any relation to the old solution. 

The second question, "what is an appropriate step size?",  is a bit more difficult to answer.
One strategy could be to simply use the results from chapter [Taylor], where we showed that the truncation error had a minimum value
with a step size of :math:`10^{-8}`  (when using a first order Taylor approximation).
How does the value :math:`10^{-8}` relate to the step sizes in minutes used in our Euler implementation?
In order to see the connection, we need to rewrite equation :ref:`(258) <Eq:eq:ode:cstr2>` in a dimensionless form,
by making the following substitution:
 :math:`t\to t/\tau`:

.. _Eq:eq:ode:cstr2dim:

.. math::

    \tag{264}
    \frac{dC(\tau)}{d\tau} = \left[C_\text{in}(\tau) - C(\tau)\right].\
        

As we found earlier $\tau = 1000$min, thus a step size of e.g. 1 min would correspond to a dimensionless time step of 
$\Delta t\to$1min/1000min$=10^{-3}$. This number can be directly compared to the value :math:`10^{-8}`, which is the lowest value we can
choose without getting into trouble with round off errors on the machine. 

.. admonition:: Dimensionless variables

   It is a  good idea to formulate our equations in terms of dimensionless variables.
   The algorithms we develop can then be used in the same form regardless of changes in the system size and flow rates.
   Thus we do not need to rewrite the algorithm each time the physical system changes. This also means that if you use
   an algorithm developed by someone else (e.g. in Matlab or Python), you should always formulate the ODE system in dimensionless form before using the algorithm.
   
   A second reason is that from a pure modeling point of view, dimensionless variables is a way of getting some
   understanding of what kind of combination of the physical parameters that describes the behavior of the system.
   For the case of the CSTR, there is a time scale :math:`\tau=V/q`, which 
   is an intrinsic measure of time in the system. No matter what the flow rate through the tank or the volume of the tank is,
   it will always take  0.1$\tau$ before
   the concentration in the tank is reduced by 90%.



As already mentioned a step size of :math:`10^{-8}`, is probably the smallest we can choose with respect to round off errors, 
but it is smaller than necessary and would lead to large simulation times. 
If it takes 1 second to run the simulation with a step size of :math:`10^{-3}`, it would take :math:`10^5` seconds or 1 day
with a step size of :math:`10^{-8}`. 
To continue the error analyses, we write our ODE for a general system as:

.. _Eq:eq:ode:ode:

.. math::

    \tag{265}
    \frac{dy}{dt}=f(y,t),
        

or in discrete form:

.. math::
        
        \frac{y_{n+1}-y_n}{h}-\frac{h}{2}y^{\prime\prime}(\eta_n)=f(y,t).\nonumber
        

.. _Eq:_auto98:

.. math::

    \tag{266}
    y_{n+1}=y_n+hf(y,t)+\frac{h^2}{2}y^{\prime\prime}(\eta_n).
        
        

:math:`h` is now the (dimensionless) step size, equal to :math:`\Delta t` if the derivative is with respect to :math:`t` or :math:`\Delta x` if the derivative is respect to :math:`x` etc. Note that we
have also included the error term related to the numerical derivative, :math:`\eta_n\in[t_n,t_n+h]`. At each step we get an error term,
and the distance between the true solution and our estimate, the *local error*, after :math:`N` steps is:

.. math::
        
        \epsilon=\sum_{n=0}^{N-1}\frac{h^2}{2}y^{\prime\prime}(\eta_n)=\frac{h^2}{2}\sum_{n=0}^{N-1}f^\prime(y_n,\eta_n)\simeq\frac{h}{2}\int_{t_0}^{t_f}f^\prime(y,\eta)d\eta\nonumber
        

.. _Eq:eq:ode:eu3:

.. math::

    \tag{267}
    =\frac{h}{2}\left[f(y(t_f),t_f)-f(y(t_0),t_0)\right].\
        

Note that when we replace the sum with an integral in the equation above, this is only correct if the step size is not too large.
From equation :ref:`(267) <Eq:eq:ode:eu3>`
we see that even if the error term on the numerical derivative is :math:`h^2`, the local error is proportional to :math:`h`
(one order lower). This is because we accumulate errors for each step.

In the following we specialize to the CSTR, to see if we can gain some additional insight. First we change variables in 
equation :ref:`(259) <Eq:eq:ode:cstr3>`: :math:`y=C(t)/C_0`, and :math:`x=t/\tau`, hence:

.. _Eq:eq:ode:simple:

.. math::

    \tag{268}
    \frac{dy}{dx}=-y.\
        

The solution to this equation is :math:`y(x)=e^{-x}`, substituting back for the new variables :math:`y` and :math:`x`, we reproduce the result in equation :ref:`(260) <Eq:eq:ode:sol>`. 
The local error, equation :ref:`(267) <Eq:eq:ode:eu3>`, reduces to:

.. _Eq:eq:ode:eu4:

.. math::

    \tag{269}
    \epsilon=\frac{h}{2}\left[-y(x_f)+y(x_0)\right]=\frac{h}{2}\left[1-e^{-x_f}\right],\
        

we have assumed that :math:`x_0=t_0/\tau=0`. This gives the estimated local error at time :math:`x_f`. For :math:`x_f=0`, the 
numerical error is zero, this makes sense because at :math:`x=0` we know the exact solution because of the initial conditions. When we move further away from the initial conditions, the
numerical error increases, but equation :ref:`(269) <Eq:eq:ode:eu4>` ensures us that as long as the step size is low enough we can get as
close as possible to the true solution, since the error scales as :math:`h` (at some point we might run into trouble with round off error in the computer).

Can we prove directly that we get the analytical result? In this 
case it is fairly simple, if we use Eulers method on equation :ref:`(268) <Eq:eq:ode:simple>`, we get:

.. math::
        
        \frac{y_{n+1}-y_n}{h}=-y_nf.\nonumber
        

.. _Eq:_auto99:

.. math::

    \tag{270}
    y_{n+1}=(1-h)y_n,
        
        

or alternatively:

.. math::
        
        y_1=(1-h)y_0,\nonumber
        

.. math::
          
        y_2=(1-h)y_1=(1-h)^2y_0,\nonumber
        

.. math::
          
        \vdots\nonumber
        

.. _Eq:_auto100:

.. math::

    \tag{271}
    y_{N+1}=(1-h)^{N}y_0=(1-h)^{x_f/h}y_0.
        
        

In the last equation, we have used the the fact the number of steps, :math:`N`, is equal to the simulation time divided by the step size, hence: :math:`N=x_f/h`. From calculus,
the equation above is one of the well known limits for the exponential function: :math:`\lim_{x\to\infty}(1+k/x)^{mx}=e^{mk}`, hence:

.. _Eq:_auto101:

.. math::

    \tag{272}
    y_n=(1-h)^{x_f/h}y_0\to e^{-x_f},
        
        

when :math:`h\to0`. Below is an implementation of the Euler algorithm in this simple case, we also estimate the local error, and global error after :math:`N` steps. 

.. code-block:: python

    import matplotlib.pyplot as plt
    import numpy as np
    def euler(tf,h):
        t=[];f=[]
        ti=0.;fi=1.
        t.append(ti);f.append(fi)
        global_err=0.
        while(ti<= tf):
            ti+=h
            fi=fi*(1-h)
            global_err += abs(np.exp(-ti)-fi)
            t.append(ti);f.append(fi)
        print("error= ", np.exp(-ti)-fi," est.err=", .5*h*(1-np.exp(-ti)))
        print("global error=",global_err)
        return t,f
                                            
    t,f=euler(1,1e-5)

By changing the step size :math:`h`, you can easily verify that the local error systematically increases or decreases proportional to :math:`h`.
Something curious happens with the global error when the 
step size is changed, it does not change very much. The global error involves a second sum over the local error for each step,
which can be approximated as a second integration in equation :ref:`(269) <Eq:eq:ode:eu4>`:

.. _Eq:eq:ode:eu5:

.. math::

    \tag{273}
    \epsilon_\text{global}=\frac{1}{2}\int_{0}^{x_f}\left[-y(x)+y(0)\right]dx=\frac{1}{2}\left[x_f+e^{-x_f}-1\right].\
        

Note that the global error does not go to zero when the step size decreases, which can easily be verified by changing the step size. This is strange, but can be understood
by the following argument: when the step size decreases the local error scales as :math:`\sim h`, but the number of steps scales as :math:`1/h`, so the global error must scale as :math:`h\times 1/h`
or some constant value. Usually it is much easier to control the local error than the global error, this should be kept in mind if you ever encounter a problem where it is 
important control the global error. For the higher order methods that we will discuss later in this chapter, the global error will go to zero when :math:`h` decreases.   

The answer to our original question, ''What is an appropriate step size?'', will depend on what you want to achieve in terms of local or global error.
In most practical situations you would
specify a local error that is acceptable for the problem under investigation and then choose a step size where the local error always is lower than this value. In the 
next subsection we will investigate how to achieve this in practice.

Adaptive step size - Euler's method
-----------------------------------

.. index::
   single: Eulers method, adaptive step size

We want to be sure that we use a step size that achieves a certain accuracy in our numerical solution, but at
the same time that we do not waste simulation time using a too low step size. The following approach is similar to the one we derived for the Romberg integration, and
a special case of what is known as Richardson Extrapolation. The method is easily extended to higher order methods. 

We know that Eulers algorithm is accurate to second order. Our estimate of the new value, :math:`y_1^*`  
(where we have used a$\,{}^*$ to indicate that we have used a step size of size :math:`h`), should then be related to the true solution :math:`y(t_1)` in the following way:

.. _Eq:eq:ode:aeb0:

.. math::

    \tag{274}
    y^*_1=y(t_1)+ch^2.\
        

The constant :math:`c` is unknown, but it can be found by taking two smaller steps of size :math:`h/2`. If the steps are not too large, our new estimate
of the value :math:`y_1` will be related to the true solution as:

.. _Eq:eq:ode:aeb1:

.. math::

    \tag{275}
    y_1=y(t_1)+2c\left(\frac{h}{2}\right)^2.\
        

The factor 2 in front of :math:`c` is because we now need to take two steps, and we accumulate a total error of :math:`2c(h/2)^2=ch^2/2`. It might not be completely 
obvious that the constant :math:`c` should be the same in equation :ref:`(274) <Eq:eq:ode:aeb0>` and :ref:`(275) <Eq:eq:ode:aeb1>`. If you are not convinced, there is an exercise at the end 
of the chapter.  
We define:

.. _Eq:eq:ode:ae5:

.. math::

    \tag{276}
    \Delta\equiv y^*_1-y_1=c\frac{h^2}{2}.\
        

The truncation error in equation :ref:`(275) <Eq:eq:ode:aeb1>` is:

.. _Eq:eq:ode:ae5b:

.. math::

    \tag{277}
    \epsilon=y(t_1)-y_1=2c\left(\frac{h}{2}\right)^2=\Delta.\
        

Now we have everything we need: We want the local error to be smaller than some predefined
tolerance, :math:`\epsilon^\prime`, or equivalently 
that :math:`\epsilon\le\epsilon^\prime`. 
To achieve this we need to use an optimal step size, :math:`h^\prime`,  that gives us exactly the desired error:

.. _Eq:eq:ode:ae6:

.. math::

    \tag{278}
    \epsilon^\prime=c\frac{{h^\prime}^2}{2}.\
        

Dividing equation :ref:`(278) <Eq:eq:ode:ae6>` by equation :ref:`(277) <Eq:eq:ode:ae5b>`, we can estimate the optimal step size:

.. _Eq:eq:ode:ae7:

.. math::

    \tag{279}
    h^\prime=h\sqrt{\left|\frac{\epsilon^\prime}{\epsilon}\right|},\
        

where the estimated error, :math:`\epsilon`, is calculated from equation :ref:`(277) <Eq:eq:ode:ae5b>`.
Equation :ref:`(279) <Eq:eq:ode:ae7>` serves two purposes, if the estimated error :math:`\epsilon` is higher than the tolerance, :math:`\epsilon^\prime`, we have specified it will 
give us an estimate for the step size we should choose in order to achieve a higher accuracy, if on the other hand :math:`\epsilon^\prime > \epsilon`, then we 
get an estimate for the next, larger step. Before the implementation we note, as we did for the Romberg integration, that equation :ref:`(277) <Eq:eq:ode:ae5b>` 
also gives us an estimate for the error term in equation :ref:`(275) <Eq:eq:ode:aeb1>` as an improved estimate of :math:`y_1`. This we get for
free and will make our Euler algorithm accurate to :math:`h^3`, hence the improved Euler step, :math:`\hat{y_1}`, is to *subtract* the error
term from our previous estimate:

.. _Eq:_auto102:

.. math::

    \tag{280}
    \hat{y_1}=y_1-\epsilon=2y_1-y_1^*.
        
        

Below is an implementation of the adaptive Euler algorithm:

.. code-block:: python

    def one_step(c_old, c_in,h):
        return (1-h)*c_old+h*c_in
    
    def adaptive_euler(c_into,c_init,t_final,tol=1e-4):
        f=[];t=[]
        c_in    = c_into #freshwater into tank
        c_old   = c_init #seawater present 
        ti=0.; h_new=1e-3;
        no_steps=0
        global_err=0.
        while(ti <= t_final):
            t.append(ti); f.append(c_old)
            toli=10.*tol; # a high init tolerance to enter while loop
            while(toli>tol):# first two small steps
                hi=h_new
                k1 = one_step(c_old,c_in,hi*.5)
                k2 = one_step(k1,c_in,hi*.5)
                # ... and one large step
                k3 = one_step(c_old,c_in,hi)
                toli = abs(k3-k2)
                h_new=hi*np.sqrt(tol/toli)
                no_steps+=3
            toli=1.
            c_old=2*k2-k3 # higher order correction
     # normal Euler, uncomment and inspect the global error
     #       c_old = k2 
            ti   += hi
            global_err += abs(np.exp(-ti)-c_old)
        print("No steps=", no_steps, "Global Error=", global_err)
        return t,f

.. _fig:ode:adapt_euler:

.. figure:: fig-ode/adaptive_euler.png
   :width: 800

   *The concentration in the tank using adaptive Euler. Number of Euler steps are: 3006, 117, 48 and 36 for the different step sizes*

In figure :ref:`fig:ode:adapt_euler` the result of the implementation is shown. 
Note that the number of steps for an accuracy of :math:`10^{-6}` is only about 3000. Without knowing anything about the accuracy, we would have to assume
that we needed a step size of the order of :math:`h` in order to reach a local accuracy of :math:`h` because of equation :ref:`(267) <Eq:eq:ode:eu3>`. In the current case,
we would have needed :math:`10^7` steps, which would lead to unnecessary long simulation times.

.. admonition:: Local error and bounds

   In the previous example we set an absolute tolerance, and required that our estimate :math:`y_n` always is within a certain bound
   of the true  solution :math:`y(t_n)`, i.e. :math:`|y(t_n)-y_n|\le\epsilon^\prime`. This is a very strong demand, and sometimes it makes more 
   sense to require that we also accept a relative tolerance proportional to function value. In some areas the solution might have a very large
   value, and then another possibility would be to have an :math:`\epsilon^\prime` that varied with the function value: :math:`\epsilon^\prime = atol +|y|rtol`, where 'atol' is the absolute tolerance and 'rtol' is the relative tolerance. A sensible choice would be to set 'atol=rtol' (e.g. = :math:`10^{-4}`).




Runge-Kutta methods
===================

.. index:: Runge-Kutta

.. _fig:ode:rk:

.. figure:: fig-ode/rk_fig.png
   :width: 800

   Illustration of the Euler algorithm, and a motivation for using the slope a distance from the :math:`t_n`

The Euler method only have an accuracy of order :math:`h`, and a global error that do not go to zero as the step size decrease. 
The Runge-Kutta methods may be motivated by inspecting the Euler method in figure :ref:`fig:ode:rk`. The Euler method uses information from
the previous time step to estimate the value at the new time step. The Runge Kutta methods uses the information about the slope between the
points :math:`t_n` and :math:`t_n+h`. By inspecting figure :ref:`fig:ode:rk`, we clearly see that by using the slope at :math:`t_n+h/2` would give us a
significant improvement. The 2. order Runge-Kutta method can be derived by Taylor expanding the solution around :math:`t_n+h/2`, we do this by
setting :math:`t_n+h=t_n+h/2+h/2`:

.. _Eq:eq:ode:rk1:

.. math::

    \tag{281}
    y(t_n+h)=y(t_n+\frac{h}{2})+\frac{h}{2}\left.\frac{dy}{dt}\right|_{t=t_n+h/2}+\frac{h^2}{4}\left.\frac{d^2y}{dt^2}\right|_{t=t_n+h/2}
        +\mathcal{O}(h^3).\
        

Similarly we can expand the solution in :math:`y(t_n)` about :math:`t_n+h/2`, by setting :math:`t_n=t_n+h/2-h/2`:

.. _Eq:eq:ode:rk2:

.. math::

    \tag{282}
    y(t_n)=y(t_n+\frac{h}{2})-\frac{h}{2}\left.\frac{dy}{dt}\right|_{t=t_n+h/2}+\frac{h^2}{4}\left.\frac{d^2y}{dt^2}\right|_{t=t_n+h/2}
        -\mathcal{O}(h^3).\
        

Subtracting these two equations the term :math:`y(t_n+\frac{h}{2})`, and all even powers in the derivative cancels out:

.. math::
        
        y(t_n+h)=y(t_n)+h\left.\frac{dy}{dt}\right|_{t=t_n+h/2}+\mathcal{O}(h^3),\nonumber
        

.. _Eq:eq:ode:rk3:

.. math::

    \tag{283}
    y(t_n+h)=y(t_n)+hf(y_{n+h/2},t_n+h/2)+\mathcal{O}(h^3).\
        

In the last equation, we have used equation :ref:`(265) <Eq:eq:ode:ode>`. Note that we now have an expression that is very similar to Eulers algorithm,
but it is accurate to order :math:`h^3`. There is one problem, and that is that the function :math:`f` is to be evaluated at the point :math:`y_{n+1/2}=y(t_n+h/2)`
which we do not know. This can be fixed by using Eulers algorithm: :math:`y_{n+1/2}=y_n+h/2f(y_n,t_n)`. We can do this even if Eulers algorithm has an error term of order :math:`h^2`, because the :math:`f` in equation :ref:`(283) <Eq:eq:ode:rk3>` is multiplied by :math:`h`, and thus our algorithm is still has an error term of order :math:`h^3`. 

.. admonition:: The 2. order Runge-Kutta

   
   .. math::
           
           k_1=hf(y_n,t_n)\nonumber
           
   
   .. math::
             
           k_2=hf(y_n+\frac{1}{2}k_1,t_n+h/2)\nonumber
           
   
   .. _Eq:eq:ode:rk4:

.. math::

    \tag{284}
    y_{n+1}=y_n+k_2\



Below is a Python implementation of equation :ref:`(284) <Eq:eq:ode:rk4>`:

.. code-block:: python

    def fm(c_old,c_in):
        return c_in-c_old
    
    def rk2_step(c_old, c_in, h):
        k1=h*fm(c_old,c_in)
        k2=h*fm(c_old+0.5*k1,c_in)
        return c_old+k2
    
    def ode_solv(c_into,c_init,t_final,h):
        f=[];t=[]
        c_in  = c_into #freshwater into tank
        c_old = c_init #seawater present 
        ti=0.
        while(ti <= t_final):
            t.append(ti); f.append(c_old)
            c_new = rk2_step(c_old,c_in,h)     
            c_old = c_new
            ti   += h
        return t,f

.. _fig:ode:rk2:

.. figure:: fig-ode/rk2.png
   :width: 800

   The concentration in the tank for different step size :math:`\Delta t`

In figure :ref:`fig:ode:rk2` the result of the implementation is shown. 
Note that when comparing Runge-Kutta 2. order with Eulers method,
see figure :ref:`fig:ode:rk2` and :ref:`fig:ode:euler`,
we of course have 
the obvious result that a larger step size can be taken, without loosing numerical accuracy. It is also worth noting that we can take steps that
is larger than the tank volume. Eulers method failed whenever the time step was larger than one tank volume (:math:`h=t/\tau>1`), whereas the Runge-Kutta 
method finds a physical solution for step sizes lower than twice the tank volume. If the step size is larger, we see that the concentration in the tank
increases, which is clearly unphysical. 

The Runge-Kutta fourth order method is one of he most used methods, it is accurate to order :math:`h^4`, and has an error of order :math:`h^5`. The development of the 
algorithm itself is similar to the 2. order method, but of course more involved. We just quote the result:

.. admonition:: The 4. order Runge-Kutta

   
   .. math::
           
           k_1=hf(y_n,t_n)\nonumber
           
   
   .. math::
             
           k_2=hf(y_n+\frac{1}{2}k_1,t_n+h/2)\nonumber
           
   
   .. math::
             
           k_3=hf(y_n+\frac{1}{2}k_2,t_n+h/2)\nonumber
           
   
   .. math::
             
           k_4=hf(y_n+k_3,t_n+h)\nonumber
           
   
   .. _Eq:eq:ode:rk5:

.. math::

    \tag{285}
    y_{n+1}=y_n+\frac{1}{6}(k_1+2k_2+2k_3+k_4)\



In figure :ref:`fig:ode:rk4` the result of the Runge-Kutta fourth order is shown, by comparing it to figure :ref:`fig:ode:rk2` it is easy to see that a larger step size can be chosen.     

.. Below is a Python implementation of equation :ref:`(285) <Eq:eq:ode:rk5>`:

.. @@@CODE src-ode/rk4.py  fromto: def fm@# rest

.. _fig:ode:rk4:

.. figure:: fig-ode/rk4.png
   :width: 800

   The concentration in the tank for different step size :math:`\Delta t`

.. % endif

Adaptive step size - Runge-Kutta method
---------------------------------------

.. index::
   single: Runge-Kutta, adaptive step size

Just as we did with Eulers method, we can implement an adaptive method. The derivation is exactly the same, but this time our method is accurate to
fourth order, hence the error term is of order :math:`h^5`. We start by taking one large step of size :math:`h`, our estimate, :math:`y_1^*` is related to the true 
solution, :math:`y(t_1)`, in the following way:

.. _Eq:eq:ode:rka0:

.. math::

    \tag{286}
    y^*_1=y(t_1)+ch^5,\
        

Next, we take two steps of half the size, :math:`h/2`, hence:

.. _Eq:eq:ode:rka1:

.. math::

    \tag{287}
    y_1=y(t)+2c\left(\frac{h}{2}\right)^5.\
        

Subtracting equation :ref:`(286) <Eq:eq:ode:rka0>` and :ref:`(287) <Eq:eq:ode:rka1>`, we find an expression similar to equation :ref:`(276) <Eq:eq:ode:ae5>`:

.. _Eq:eq:ode:rka2:

.. math::

    \tag{288}
    \Delta\equiv y_1^*-y_1=c\frac{15}{16}h^5,\
        

or :math:`c=16\Delta/(15h^5)`. For the Euler scheme, :math:`\Delta` also happened to be equal to the truncation error, but in this case it is:

.. _Eq:eq:ode:rka5:

.. math::

    \tag{289}
    \epsilon=2c\left(\frac{h}{2}\right)^5=\frac{\Delta}{15}\
        

we want the local error, :math:`\epsilon`, to be smaller than some tolerance, :math:`\epsilon^\prime`.  
The optimal step size, :math:`h^\prime`,  that gives us exactly the desired error is then:

.. _Eq:eq:ode:rka3:

.. math::

    \tag{290}
    \epsilon^\prime=2c\left(\frac{{h^\prime}}{2}\right)^5.\
        

Dividing equation :ref:`(290) <Eq:eq:ode:rka3>` by equation :ref:`(289) <Eq:eq:ode:rka5>`, we can estimate the optimal step size:

.. _Eq:eq:ode:rka4:

.. math::

    \tag{291}
    h^\prime=h\left|\frac{\epsilon}{\epsilon}\right|^{1/5},\
        

:math:`\epsilon` can be calculated from equation :ref:`(289) <Eq:eq:ode:rka5>`. In figure :ref:`fig:ode:adaptive_rk4` the result of an  implementation is shown (see the exercises). 

.. Below is an implementation

.. % if FORMAT == 'ipynb':

.. Run the script below and inspect the results.

.. @@@CODE src-ode/rk4.py

.. % endif

.. % if FORMAT != 'ipynb':

.. @@@CODE src-ode/adaptive_rk4.py  fromto: def fm@# rest

.. _fig:ode:adaptive_rk4:

.. figure:: fig-ode/adaptive_rk4.png
   :width: 800

   *The concentration in the tank for different step size :math:`\Delta t`. Number of rk4 steps are: 138, 99, 72 and 66 for the different step sizes and 'rtol=0', for 'rtol=tol' the number of rk4 steps are 81, 72, 63, 63*

.. % endif

In general we can use the same procedure any method accurate to order :math:`h^p`, and you can easily verify that:

.. admonition:: Error term and step size for a :math:`h^p` method

   
   .. index:: adaptive step size
   
   .. _Eq:eq:eode:1:

.. math::

    \tag{292}
    |\epsilon|=\frac{|\Delta|}{2^p-1}=\frac{|y_1^*-y_1|}{2^p-1},
           
   
   .. _Eq:eq:eode:2:

.. math::

    \tag{293}
    h^\prime=\beta h\left|\frac{\epsilon}{\epsilon_0}\right|^{\frac{1}{p+1}},
           
   
   .. _Eq:eq:eode:3:

.. math::

    \tag{294}
    \hat{y_1}=y_1-\epsilon=\frac{2^p y_1-y_1^*}{2^{p}-1},
           
   
   where :math:`\beta` is a safety factor :math:`\beta\simeq0.8,0.9`, and you should always be careful that the step size do not become too large so that
   the method breaks down. This can happens when :math:`\epsilon` is very low, which may happen if :math:`y_1^*\simeq y_1` and/or if :math:`y_1^*\simeq y_1\simeq 0`.




Conservation of mass
--------------------
A mathematical model of a physical system should always be formulated in such a way that it is
consistent with the laws of nature. In practical situations this statement is usually equivalent to state that
the mathematical model should respect conservation laws. The conservation laws can be conservation of mass, energy, momentum, 
electrical charge, etc. In our
example with the mixing tank, we were able to derive an expression for the concentration of salt out of
the tank, equation :ref:`(260) <Eq:eq:ode:sol>`, by *demanding* conservation of mass (see equation :ref:`(257) <Eq:eq:ode:cstr1>`).

A natural question to ask is then: If our mathematical model respect conservation of mass, are we sure that our 
solution method respect conservation of mass? We of course expect that
when the grid spacing approaches zero our numerical solution will get closer and closer to the analytical
solution. Clearly when :math:`\Delta x\to 0`, the mass is conserved. So what is the problem? The problem is that in many practical problems
we cannot always have a step size that is small enough to ensure that our solution always is close enough to the analytical 
solution. The physical system we consider might be very complicated (e.g. a model for the earth climate), and our ODE system could
be a very small part of a very big system. A very good test of any code is to investigate if the code respect
the conservation laws. If we know that our implementation respect e.g. mass conservation at the discrete level, we can easily
test mass conservation by summing up all the mass entering, and subtracting the mass out of and present in our system.
If the mass is not conserved exactly, there is a good chance that there is a bug in our implementation.

If we now turn to our system, we know that the total amount of salt in the system when we start is :math:`C(0)V`.
The amount entering is zero, and the amount leaving each time step is :math:`q(t)C(t)\Delta t`. Thus we should
expect that if we add the amount of salt in the tank to the amount that has left the system
we should always get an amount that is equal to the original amount. Alternatively, we expect
:math:`\int_{t_0}^t qC(t)dt + C(t)V -C(0)V=0`. Adding the following code in the ``while(ti <= t_final):`` loop:

.. code-block:: python

    mout += 0.5*(c_old+c_new)*q*dt
    mbal  = (c_new*vol+mout-vol*c_init)/(vol*c_init)

it is possible to calculate the amount of mass lost (note that we have used the
trapezoidal formula to calculate the integral). In the table below the fraction of mass lost relative to the original
amount is shown for the various numerical methods.

===========  =========  =======  ===========  ===========  
﻿$\Delta t$  :math:`h`   Euler   RK 2. order  RK 4. order  
===========  =========  =======  ===========  ===========  
    900         0.9     -0.4500     0.3682       0.0776    
    500         0.5     -0.2500     0.0833       0.0215    
    100         0.1     -0.0500     0.0026       0.0008    
     10         0.01    -0.0050    2.5E-05      8.3E-06    
===========  =========  =======  ===========  ===========  

We clearly see from the table that the Runge-Kutta methods performs better than Eulers method, but
*all of the methods violates mass balance*. 

This might not be a surprise as we know that our numerical solution is always an approximation to the analytical solution. How can 
we then formulate an algorithm that will respect conservation laws at the discrete level? It turns out that for Eulers method it is not
so difficult. Eulers algorithm at the discrete level (see equation :ref:`(261) <Eq:eq:ode:eu0>`) is actually a two-step process: first we inject the fresh water while we remove the ``old`` fluid *and then we mix*. By thinking about the
problem this way, it makes more sense to calculate the mass out of the tank as :math:`\sum_kq_kC_k\Delta t_k`. If we in our implementation calculates the mass out of the tank as:

.. code-block:: python

    mout += c_old*q*dt
    mbal  = (c_new*vol+mout-vol*c_init)/(vol*c_init)

We easily find that the mass is exactly conserved at every time for Eulers method. The concentration in the tank will of course not be any closer to the 
analytical solution, but if our mixing tank was part of a much bigger system we could make sure that the mass would always be conserved if we make
sure that the mass out of the tank and into the next part of the system was equal to :math:`qC(t)\Delta t`. 

Solving a set of ODE equations
==============================
What happens if we have more than one equation that needs to be solved? If we continue with our current example, we might be interested in what would happen 
if we had multiple tanks in series. This could be a very simple model to describe the cleaning  of a salty lake by injecting fresh water into it, but at 
the same time this lake was connected to two nearby fresh water lakes, as illustrated in figure :ref:`fig:ode:cstr3`. The weakest part of the model is the assumption about 
complete mixing, in a practical situation we could enforce complete mixing with the salty water in the first tank by injecting fresh water at multiple point in the 
lake. For the two next lakes, the degree of mixing is not obvious, but salt water is heavier than fresh water and therefore it would sink and mix with the fresh water. Thus
if the flow rate was slow, one might imaging that a more or less complete mixing could occur. Our model then could answer questions like, how long time would it take before most
of the salt water is removed from the first lake, and how much time would it take before most of the salt water was cleared from the whole system? The answer to 
these questions would give practical input on how much and how fast one should inject the fresh water to clean up the system. If we had 
data from an actual system, we could compare our model predictions with data from the physical system, and investigate if our model description was correct. 

.. _fig:ode:cstr3:

.. figure:: fig-ode/cstr3.png
   :width: 800

   *A simple model for cleaning a salty lake that is connected to two lakes down stream*

For simplicity we will assume that all the lakes have the same volume, :math:`V`. The governing equations follows
as before, by assuming mass balance (equation :ref:`(256) <Eq:eq:ode:mbal>`):

.. math::
        
        C_0(t+\Delta t)\cdot V - C_0(t)\cdot V = q(t)\cdot C_\text{in}(t)\cdot \Delta t - q(t)\cdot C_0(t)\cdot \Delta t,\nonumber
        

.. math::
          
        C_1(t+\Delta t)\cdot V - C_1(t)\cdot V = q(t)\cdot C_0(t)\cdot \Delta t - q(t)\cdot C_1(t)\cdot \Delta t,\nonumber
        

.. _Eq:eq:ode:cstr3a:

.. math::

    \tag{295}
    C_2(t+\Delta t)\cdot V - C_2(t)\cdot V = q(t)\cdot C_1(t)\cdot \Delta t - q(t)\cdot C_2(t)\cdot \Delta t.\
        

Taking the limit :math:`\Delta t\to 0`, we can write equation :ref:`(295) <Eq:eq:ode:cstr3a>` as:

.. _Eq:eq:ode:cstr3b:

.. math::

    \tag{296}
    V\frac{dC_0(t)}{dt} = q(t)\left[C_\text{in}(t) - C_0(t)\right],\
        

.. _Eq:eq:ode:cstr3c:

.. math::

    \tag{297}
    V\frac{dC_1(t)}{dt} = q(t)\left[C_0(t) - C_1(t)\right],\
        

.. _Eq:eq:ode:cstr3d:

.. math::

    \tag{298}
    V\frac{dC_2(t)}{dt} = q(t)\left[C_1(t) - C_2(t)\right].\
        

Let us first derive the analytical solution: Only the first tank is filled with salt water :math:`C_0(0)=C_{0,0}`, :math:`C_1(0)=C_2(0)=0`, and :math:`C_\text{in}=0`. 
The solution to equation :ref:`(296) <Eq:eq:ode:cstr3b>` is, as before :math:`C_0(t)=C_{0,0}e^{-t/\tau}`, inserting this equation into equation :ref:`(297) <Eq:eq:ode:cstr3c>` we find:

.. _Eq:eq:ode:cstr3e:

.. math::

    \tag{299}
    V\frac{dC_1(t)}{dt} = q(t)\left[C_{0,0}e^{-t/\tau} - C_1(t)\right]\,
        

.. _Eq:eq:ode:cstr3f:

.. math::

    \tag{300}
    \frac{d}{dt}\left[e^{t/\tau}C_1\right]= \frac{C_{0,0}}{\tau}\,
        

.. _Eq:eq:ode:cstr3g:

.. math::

    \tag{301}
    C_1(t)=\frac{C_{0,0}t}{\tau}e^{-t/\tau}\.
        

where we have use the technique of `integrating factors <https://en.wikipedia.org/wiki/Integrating_factor>`__ when going from equation :ref:`(299) <Eq:eq:ode:cstr3e>` to :ref:`(300) <Eq:eq:ode:cstr3f>`. 
Inserting equation :ref:`(301) <Eq:eq:ode:cstr3g>` into equation :ref:`(298) <Eq:eq:ode:cstr3d>`, solving the equation in a similar way as for :math:`C_1` we find:

.. _Eq:eq:ode:cstr3h:

.. math::

    \tag{302}
    V\frac{dC_2(t)}{dt} = q(t)\left[\frac{C_{0,0}t}{\tau}e^{-t/\tau} - C_2(t)\right],\
        

.. _Eq:eq:ode:cstr3i:

.. math::

    \tag{303}
    \frac{d}{dt}\left[e^{t/\tau}C_2\right]= \frac{C_{0,0}t}{\tau},\
        

.. _Eq:eq:ode:cstr3j:

.. math::

    \tag{304}
    C_2(t)=\frac{C_{0,0}t^2}{2\tau^2}e^{-t/\tau}.\
        

The numerical solution follows the exact same pattern as before if we introduce a vector notation. Before doing that, we rescale the time :math:`t\to t/\tau` and the concentrations,
 :math:`\hat{C_i}=C_i/C_{0,0}` for :math:`i=0,1,2`, hence:

.. math::
        
        \frac{d}{dt}
        \left(
        \begin{array}{c} 
         \hat{C_0}(t)\\ 
         \hat{C_1}(t)\\ 
         \hat{C_2}(t)
         \end{array}
         \right)
        =\left(
        \begin{array}{c} 
         \hat{C_\text{in}}(t) - \hat{C_0}(t)\\ 
         \hat{C_0}(t) - \hat{C_1}(t)\\ 
         \hat{C_1}(t) - \hat{C_2}(t)
         \end{array}
         \right),\nonumber
         
        

.. _Eq:_auto103:

.. math::

    \tag{305}
    \frac{d\mathbf{\hat{C}}(t)}{dt}=\mathbf{f}(\mathbf{\hat{C}},t).
        
        
        

In figure :ref:`fig:ode:rk4_2` results of an implementation using Runge-Kutta 4. order is shown (see exercises for more details).

.. Below is an implementation using the Runge Kutta 4. order method:

.. % if FORMAT == 'ipynb':

.. Run the script below and inspect the results.

.. @@@CODE src-ode/rk4_2.py

.. % endif

.. % if FORMAT != 'ipynb':

.. @@@CODE src-ode/rk4_2.py  fromto: def fm@# rest

.. _fig:ode:rk4_2:

.. figure:: fig-ode/rk4_2.png
   :width: 800

   *The concentration in the tanks*

.. % endif

Stiff sets of ODE  and implicit methods
=======================================

.. index:: stiff equations

.. index:: implicit method

As already mentioned a couple of times, our system could be part of a much larger system. To illustrate this, let us now assume that we have two 
tanks in series. The first tank is similar to our original tank, but the second tank is a sampling tank, 1000 times smaller.   

.. _fig:ode:cstr2:

.. figure:: fig-ode/cstr2.png
   :width: 800

   *A continuous stirred tank model with a sampling vessel*

The governing equations can be found by requiring mass balance for each of the tanks (see equation :ref:`(256) <Eq:eq:ode:mbal>`:

.. math::
        
        C_0(t+\Delta t)\cdot V_0 - C_0(t)\cdot V_0 = q(t)\cdot C_\text{in}(t)\cdot \Delta t - q(t)\cdot C_0(t)\cdot \Delta t.\nonumber
        

.. _Eq:eq:ode:cstr2a:

.. math::

    \tag{306}
    C_1(t+\Delta t)\cdot V_1 - C_1(t)\cdot V_1 = q(t)\cdot C_0(t)\cdot \Delta t - q(t)\cdot C_1(t)\cdot \Delta t.
        \
        

Taking the limit :math:`\Delta t\to 0`, we can write equation :ref:`(306) <Eq:eq:ode:cstr2a>` as:

.. _Eq:eq:ode:cstr2bb:

.. math::

    \tag{307}
    V_0\frac{dC_0(t)}{dt} = q(t)\left[C_\text{in}(t) - C_0(t)\right].\
        

.. _Eq:eq:ode:cstr2b:

.. math::

    \tag{308}
    V_1\frac{dC_1(t)}{dt} = q(t)\left[C_0(t) - C_1(t)\right].\
        

Assume that the first tank is filled with seawater, :math:`C_0(0)=C_{0,0}`, and fresh water is flooded into the tank, i.e. :math:`C_\text{in}=0`. Before we start to consider a numerical
solution, let us first find the analytical solution: As before the solution for the first tank (equation :ref:`(307) <Eq:eq:ode:cstr2bb>`) is:

.. _Eq:_auto104:

.. math::

    \tag{309}
    C_0(t)=C_{0,0}e^{-t/\tau_0},
        
        

where :math:`\tau_0\equiv V_0/q`. Inserting this equation into equation :ref:`(308) <Eq:eq:ode:cstr2b>`, we get:

.. math::
        
        \frac{dC_1(t)}{dt} = \frac{1}{\tau_1}\left[C_{0,0}e^{-t/\tau_0} - C_1(t)\right],\nonumber
        

.. _Eq:eq:ode:cstr2c:

.. math::

    \tag{310}
    \frac{d}{dt}\left[e^{t/\tau_2}C_1\right]= \frac{C_{0,0}}{\tau_1}e^{-t(1/\tau_0-1/\tau_1)}\,
        

.. _Eq:eq:ode:cstr2d:

.. math::

    \tag{311}
    C_1(t)=\frac{C_{0,0}}{1-\frac{\tau_1}{\tau_0}}\left[e^{-t/\tau_0}-e^{-t/\tau_1}\right],\
        

where :math:`\tau_1\equiv V_1/q`.

Next, we will consider the numerical solution. You might think that these equations are more simple to solve numerically than the equations with three tanks
in series discussed in the previous section. Actually, this system is much harder to solve with the methods we have discussed so far.
The reason is that there are now *two time scales* in the system, :math:`\tau_1` and :math:`\tau_2`. The smaller tank sets a strong limitation on the step size
we can use, because we should never use step sizes larger than a tank volume. Thus if you use the code in the previous section to solve equation
:ref:`(307) <Eq:eq:ode:cstr2bb>` and :ref:`(308) <Eq:eq:ode:cstr2b>`, it will not find the correct solution, unless the step size is lower than :math:`10^{-3}`. Equations of this type
are known as *stiff*. 

.. admonition:: Stiff equations

   There is no precise definition of ''stiff'', but it is used to describe a system of differential equations, where the numerical solution becomes unstable unless
   a very small step size is chosen. Such systems occurs because there are several (length, time) scales in the system, and the numerical solution is constrained
   by the shortest length scale. You should always be careful on how you scale your variables in order to make the system dimensionless, which is of 
   particular importance when you use adaptive methods.




These types of equations are often encountered in practical applications. If our sampling tank was extremely small, maybe :math:`10^6` smaller than the chemical
reactor, then we would need a step size of the order of :math:`10^{-8}` or lower to solve the system. This step size is so low that we easily run into trouble
with round off errors in the computer. In addition the simulation time is extremely long.  How do we deal with this problem? The solution is actually
quite simple. The reason we run into trouble is that we require that the concentration leaving the tank must be a small perturbation of the old one.
This is not necessary, and it is best illustrated with Eulers method. As explained earlier Eulers method can be viewed as a two step process:
first we inject a volume (and remove an equal amount: :math:`qC(t)\Delta t`), and then we mix. Clearly when we try to remove more than what is left, we run into
trouble. What we want to do is to remove or flood much more than one tank volume through the tank during one time step, this can be achieved by
:math:`q(t)C(t)\Delta t\to q(t+\Delta t)C(t+\Delta t)\Delta t`. The term :math:`q(t+\Delta t)C(t+\Delta t)\Delta t` now represents
*the mass out of the system during the time step $\Delta t$*.

The methods we have considered so far are known as *explicit*, whenever we replace the solution in the right hand side of our algorithm with :math:`y(t+\Delta t)`
or (:math:`y_{n+1}`),
the method is known as *implicit*. Implicit methods are always stable, meaning that we can take as large a time step that we would like, without
getting oscillating solution. It does not mean that we will get a more accurate solution, actually explicit methods are usually more accurate.


.. admonition:: Explicit and Implicit methods

   Explicit methods are often called *forward* methods, as they use only information from the previous step to estimate the next value. The explicit
   methods are easy to implement, but get into trouble if the step size is too large. Implicit methods are often called *backward* methods as the next 
   step cannot be calculated directly from the previous solution, usually a non-linear equation has to be solved. Implicit methods are generally much
   more stable, but the price is often lower accuracy. Many commercial simulators uses implicit methods extensively because they are stable, and stability is often viewed
   as a much more important criterion than numerical accuracy.



Let us consider our example further, and for simplicity use the implicit Eulers method:

.. math::
        
        {C_0}_{n+1}V_0 - {C_0}_nV_0 = q(t+\Delta t){C_\text{in}}_{n+1}\Delta t -
        q(t+\Delta t){C_0}_{n+1}\Delta t.\nonumber
        

.. _Eq:eq:ode:cstr2ai:

.. math::

    \tag{312}
    {C_1}_{n+1}V_1 - {C_1}_nV_1 = q(t+\Delta t){C_0}_{n+1}\Delta t - q(t+\Delta t){C_1}_{n+1}\Delta t.
        \
        

This equation is equal to equation :ref:`(306) <Eq:eq:ode:cstr2a>`, but the concentrations on the right hand side are now evaluated at the next time step.
The immediate problem is now that we have to find an expression for :math:`C_{n+1}` that is given in terms of known variables. In most cases one needs
to use a root finding method, like Newtons method, in order to solve equation :ref:`(312) <Eq:eq:ode:cstr2ai>`. In this case it is straight forward to show:

.. math::
        
        {C_0}_{n+1}=\frac{{C_0}_n + \frac{\Delta t}{\tau_0}{C_\text{in}}_{n+1}}{1+\frac{\Delta t}{\tau_0}},\nonumber
        

.. _Eq:eq:ode:cstri1:

.. math::

    \tag{313}
    {C_2}_{n+1}=\frac{{C_1}_n + \frac{\Delta t}{\tau_1}{C_0}_{n+1}}{1+\frac{\Delta t}{\tau_1}}.\
        

In figure :ref:`fig:ode:euler_imp` the result of the implementation is shown, note that quite large step sizes can be used without inducing non physical results.

.. Below is an implementation

.. % if FORMAT == 'ipynb':

.. Run the script below and inspect the results.

.. @@@CODE src-ode/euler_imp_2.py

.. % endif

.. % if FORMAT != 'ipynb':

.. @@@CODE src-ode/euler_imp_2.py  fromto: def fm@# rest

.. _fig:ode:euler_imp:

.. figure:: fig-ode/euler_imp.png
   :width: 800

   The concentration in the tanks for :math:`h=0.01`

.. % endif

.. --- begin exercise ---

Exercise 7.1: Truncation error in Euler's method
------------------------------------------------

In the following we will take a closer look at the adaptive Eulers algorithm and show that the 
constant :math:`c` is indeed the same in equation :ref:`(274) <Eq:eq:ode:aeb0>` and :ref:`(275) <Eq:eq:ode:aeb1>`. 
The true solution :math:`y(t)`, obeys the following equation:

.. _Eq:eq:ode:ay:

.. math::

    \tag{314}
    \frac{dy}{dt}=f(y,t),\
        

and Eulers method to get from :math:`y_0` to :math:`y_1` by taking one (large) step, :math:`h` is:

.. _Eq:eq:ode:ae0:

.. math::

    \tag{315}
    y^*_1=y_0+hf(y_0,t_0),\
        

We will also assume (for simplicity) that in our starting point :math:`t=t_0`, the numerical solution, :math:`y_0`, is equal to the true solution, :math:`y(t_0)`, hence :math:`y(t_0)=y_0`.

.. --- begin solution of exercise ---

**Solution.**
The local error, is the difference between the numerical solution and the true solution:

.. math::
        
        \epsilon^*=y(t_0+h)-y_{1}^*=y(t_0)+y^{\prime}(t_0)h+\frac{1}{2}y^{\prime\prime}(t_0)h^2+\mathcal{O}(h^3)\nonumber
        

.. _Eq:_auto108:

.. math::

    \tag{316}
    -\left[y_0+hf(y_0,t_0+h)\right],
        
        

where we have used Taylor expansion to expand the true solution around :math:`t_0`, and equation :ref:`(315) <Eq:eq:ode:ae0>`.
Using equation :ref:`(314) <Eq:eq:ode:ay>` to replace :math:`y^\prime(t_0)` with :math:`f(y_0,t_0)`, we find:

.. _Eq:_auto109:

.. math::

    \tag{317}
    \epsilon^*=y(t_0+h)-y_{1}^*=\frac{1}{2}y^{\prime\prime}(t_0)h^2\equiv ch^2,
        
        

where we have ignored terms of higher order than :math:`h^2`, and defined :math:`c` as :math:`c=y^{\prime\prime}(t_0)/2`. Next we take two steps of size :math:`h/2` to
reach :math:`y_1`:  

.. _Eq:eq:ode:ae1:

.. math::

    \tag{318}
    y_{1/2}=y_0+\frac{h}{2}f(y_0,t_0),\
        

.. _Eq:eq:ode:ae2:

.. math::

    \tag{319}
    y_{1}=y_{1/2}+\frac{h}{2}f(y_{1/2},t_0+h/2),\
        

.. _Eq:eq:ode:ae3:

.. math::

    \tag{320}
    y_{1}=y_{0}+\frac{h}{2}f(y_0,t_0)+\frac{h}{2}f(y_0+\frac{h}{2}f(y_0,t_0),t_0+h/2).\
        

Note that we have inserted
equation :ref:`(318) <Eq:eq:ode:ae1>` into equation :ref:`(319) <Eq:eq:ode:ae2>` to arrive at equation :ref:`(320) <Eq:eq:ode:ae3>`. The truncation error in this case is, as before:

.. math::
        
        \epsilon=y(t_0+h)-y_{1}=y(t_0)+y^{\prime}(t_0)h+\frac{1}{2}y^{\prime\prime}(t_0)h^2+\mathcal{O}(h^3)\nonumber
        

.. _Eq:eq:ode:ay5:

.. math::

    \tag{321}
    -\left[y_{0}+\frac{h}{2}f(y_0,t_0)+\frac{h}{2}f(y_0+\frac{h}{2}f(y_0,t_0),t_0+h/2)\right].\
        

This equation is slightly more complicated, due to the term involving :math:`f` inside the last parenthesis, we can use Taylor expansion to expand it about :math:`(y_0,t_0)`:

.. math::
        
        f(y_0+\frac{h}{2}f(y_0,t_0),t_0+h/2)=f(y_0,t_0)\nonumber
        

.. _Eq:eq:ode:ay2:

.. math::

    \tag{322}
    +\frac{h}{2}\left[f(y_0,t_0)\left.\frac{\partial f}{\partial y}\right|_{y=y_0,t=t_0}
        +\left.\frac{\partial f}{\partial t}\right|_{y=y_0,t=t_0}\right]+\mathcal{O}(h^2).\
        

It turns out that this equation is related to :math:`y^{\prime\prime}(t_0,y_0)`, which can be seen by differentiating equation :ref:`(314) <Eq:eq:ode:ay>`:

.. _Eq:eq:ode:ay3:

.. math::

    \tag{323}
    \frac{d^2y}{dt^2}=\frac{df(y,t)}{dt}=\frac{\partial f(y,t)}{\partial y}\frac{dy}{dt}+\frac{\partial f(y,t)}{\partial t}
        =\frac{\partial f(y,t)}{\partial y}f(y,t)+\frac{\partial f(y,t)}{\partial t}.\
        

Hence, equation :ref:`(322) <Eq:eq:ode:ay2>` can be written:

.. _Eq:eq:ode:ay4:

.. math::

    \tag{324}
    f(y_0+\frac{h}{2}f(y_0,t_0),t_0+h/2)=f(y_0,t_0)+\frac{h}{2}y^{\prime\prime}(t_0,y_0),\
        

hence the truncation error in equation :ref:`(321) <Eq:eq:ode:ay5>` can finally be written:

.. _Eq:eq:ode:ae4:

.. math::

    \tag{325}
    \epsilon=y(t_1)-y_{1}=\frac{h^2}{4} y^{\prime\prime}(y_0,t_0)=\frac{1}{2}ch^2,\
        

.. --- end solution of exercise ---

**a)**
Show that when we take one step of size :math:`h` from :math:`t_0` to :math:`t_1=t_0+h`, :math:`c=y^{\prime\prime}(t_0)/2` in equation :ref:`(274) <Eq:eq:ode:aeb0>`.

.. --- begin answer of exercise ---

**Answer.**
The local error, is the difference between the numerical solution and the true solution:

.. math::
        
        \epsilon^*=y(t_0+h)-y_{1}^*=y(t_0)+y^{\prime}(t_0)h+\frac{1}{2}y^{\prime\prime}(t_0)h^2+\mathcal{O}(h^3)\nonumber
        

.. _Eq:_auto105:

.. math::

    \tag{326}
    -\left[y_0+hf(y_0,t_0+h)\right],
        
        

where we have used Taylor expansion to expand the true solution around :math:`t_0`, and equation :ref:`(315) <Eq:eq:ode:ae0>`.
Using equation :ref:`(314) <Eq:eq:ode:ay>` to replace :math:`y^\prime(t_0)` with :math:`f(y_0,t_0)`, we find:

.. _Eq:_auto106:

.. math::

    \tag{327}
    \epsilon^*=y(t_0+h)-y_{1}^*=\frac{1}{2}y^{\prime\prime}(t_0)h^2\equiv ch^2,
        
        

hence :math:`c=y^{\prime\prime}(t_0)/2`.

.. --- end answer of exercise ---

**b)**
Show that when we take two steps of size :math:`h/2` from :math:`t_0` to :math:`t_1=t_0+h`, Eulers algorithm is:

.. _Eq:_auto107:

.. math::

    \tag{328}
    y_{1}=y_{0}+\frac{h}{2}f(y_0,t_0)+\frac{h}{2}f(y_0+\frac{h}{2}f(y_0,t_0),t_0+h/2).
        
        

.. --- begin answer of exercise ---

**Answer.**

.. _Eq:eq:ode:ae1b:

.. math::

    \tag{329}
    y_{1/2}=y_0+\frac{h}{2}f(y_0,t_0),\
        

.. _Eq:eq:ode:ae2b:

.. math::

    \tag{330}
    y_{1}=y_{1/2}+\frac{h}{2}f(y_{1/2},t_0+h/2),\
        

.. _Eq:eq:ode:ae3b:

.. math::

    \tag{331}
    y_{1}=y_{0}+\frac{h}{2}f(y_0,t_0)+\frac{h}{2}f(y_0+\frac{h}{2}f(y_0,t_0),t_0+h/2).\
        

Note that we have inserted
equation :ref:`(329) <Eq:eq:ode:ae1b>` into equation :ref:`(330) <Eq:eq:ode:ae2b>` to arrive at equation :ref:`(331) <Eq:eq:ode:ae3b>`.

.. --- end answer of exercise ---

**c)**
Find an expression for the local error when using two steps of size :math:`h/2`, and show that the local error is: :math:`\frac{1}{2}ch^2`

.. --- begin answer of exercise ---

**Answer.**

.. math::
        
        \epsilon=y(t_0+h)-y_{1}=y(t_0)+y^{\prime}(t_0)h+\frac{1}{2}y^{\prime\prime}(t_0)h^2+\mathcal{O}(h^3)\nonumber
        

.. _Eq:eq:ode:ay5b:

.. math::

    \tag{332}
    -\left[y_{0}+\frac{h}{2}f(y_0,t_0)+\frac{h}{2}f(y_0+\frac{h}{2}f(y_0,t_0),t_0+h/2)\right].\
        

This equation is slightly more complicated, due to the term involving :math:`f` inside the last parenthesis, we can use Taylor expansion to expand it about :math:`(y_0,t_0)`:

.. math::
        
        f(y_0+\frac{h}{2}f(y_0,t_0),t_0+h/2)=f(y_0,t_0)\nonumber
        

.. _Eq:eq:ode:ay2b:

.. math::

    \tag{333}
    +\frac{h}{2}\left[f(y_0,t_0)\left.\frac{\partial f}{\partial y}\right|_{y=y_0,t=t_0}
        +\frac{h}{2}\left.\frac{\partial f}{\partial t}\right|_{y=y_0,t=t_0}\right]+\mathcal{O}(h^2).\
        

It turns out that this equation is related to :math:`y^{\prime\prime}(t_0,y_0)`, which can be seen by differentiating equation :ref:`(314) <Eq:eq:ode:ay>`:

.. _Eq:eq:ode:ay3b:

.. math::

    \tag{334}
    \frac{d^2y}{dt^2}=\frac{df(y,t)}{dt}=\frac{\partial f(y,t)}{\partial y}\frac{dy}{dt}+\frac{\partial f(y,t)}{\partial t}
        =\frac{\partial f(y,t)}{\partial y}f(y,t)+\frac{\partial f(y,t)}{\partial t}.\
        

Hence, equation :ref:`(333) <Eq:eq:ode:ay2b>` can be written:

.. _Eq:eq:ode:ay4b:

.. math::

    \tag{335}
    f(y_0+\frac{h}{2}f(y_0,t_0),t_0+h/2)=f(y_0,t_0)+\frac{h}{2}y^{\prime\prime}(t_0,y_0),\
        

hence the truncation error in equation :ref:`(332) <Eq:eq:ode:ay5b>` can finally be written:

.. _Eq:eq:ode:ae4b:

.. math::

    \tag{336}
    \epsilon=y(t_1)-y_{1}=\frac{h^2}{4} y^{\prime\prime}(y_0,t_0)=\frac{1}{2}ch^2,\
        

.. --- end answer of exercise ---

.. --- end exercise ---

