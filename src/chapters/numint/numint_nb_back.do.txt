======= Numerical Integration Notebook =======
Learning objectives:
* being able to implement a numerical algorithm in python
* quantify numerical uncertainty
* test different methods and have basic understanding of the strength and weaknesses of each method
===== The Trapezoidal Rule =====
In the lecture notes it was shown that the algorithm for the trapezoidal rule was:
!bt
\begin{align}
I(a,b)&=\int_a^bf(x)dx\simeq h\left[\frac{1}{2}f(a)+\frac{1}{2}f(b)+\sum_{k=1}^{N-1}f(a+k h)\right].
label{eq:numint:trap1}
\end{align}
!et
===== Exercise: Implementing the trapezoidal rule in Python =====
Whenever implementing an algorithm it is always important to be absolutely sure that we have implemented it correctly. We always use functions that we know the true answer. As a test function you could use $\sin x$ or any other function (e.g. $e^x$ etc.) and choose a reasonable integration domain. First:
o Show that the analytical result is $\int_0^\pi \sin(x)dx=2$
o Show that if $N=3$, equation (ref{eq:numint:trap1}) would give $I(0,\pi)=\frac{\pi}{\sqrt{3}}=1.8137993\ldots$
Use the formula in equation (ref{eq:numint:trap1}) to develop a python function that takes as argument the integration limits ($a,b$), the function to be integrated, $f(x)$, and the number of integration points $N$:
!bc pycod
import numpy as np
def f(x):
    return np.sin(x)
    
def int_trapez(func,lower_limit, upper_limit,N):
    """ calculates the area of func over the domain (lower_limit, upper)
        limit using N integration points """
# calculate the step size from the integration limits and N, do the sum, and return the area
    return area
!ec

* Test the code for $N=3$, increase $N$ and compare with the analytical result (2).
* By increasing $N$ the numerical result will get closer to the true answer. How much do you need to increase $N$ in order to
  reach an accuracy higher than $10^{-8}$?
* Show that the error term for the trapezoidal rule is:
!bt
\begin{equation}
E_T\simeq \frac{h^2}{12}\left[f^\prime(b)-f^\prime(a)\right]=\frac{(b-a)^2}{12N^2}\left[f^\prime(b)-f^\prime(a)\right]=-\frac{\pi^2}{6N^2}
label{eq:numint:e_t}
\end{equation}
!et

* How does the numerical error compares with the analytical error?

===== Exercise: Choose number of steps automatically for the trapezoidal rule =====
In practical applications we would like to just enter the accuracy we would like, and then expect our algorithm to figure out the number of steps. Change the code in the exercise above to calculate the value of the integral using a tolerance as input, instead of $N$. (The step size can be calculated from equation (ref{eq:numint:e_t})
!bc pycod
import numpy as np
def f(x):
    return np.sin(x)
#Numerical derivative of function
def df(x,func):
    dh=1e-5 # some low step size
    return (func(x+dh)-func(x))/dh
    
def int_trapez(func,lower_limit, upper_limit,tol):
    """ calculates the area of func over the domain (lower_limit, upper)
        limit using N integration points """
# calculate the step size h from the tolerance, do the sum, and return the ares
    return area

prec=1e-8
a=0
b=np.pi
Area = int_adaptive_trapez(a,b,f,prec)
print('Numerical value = ', Area)
print('Error           = ', (2-Area)) # Analytical result is 2

!ec
===== Exercise: Practical error estimate of numerical integrals =====
Assume that we estimate an integral using a step size of $h_1$ and $h_2$ ($h_1=2h_2$). The resulting estimates are $I_1$ and $I_2$ respectively. Show that the higher order error term for $I_2$ is:
!bt
\begin{equation}
E(a,b)=c h_2^2=\frac{1}{3}(I_2-I_1).
\end{equation}
!et

Make a Python implementation of the trapezoidal rule that uses this method to calculate the integral to a specific tolerance:
!bc pycod
def int_adaptive_trapez(func, lower_limit, upper_limit,tol):
    N0      = 1 # first estimate of integral
    h       = (upper_limit-lower_limit)/N0
    area    = func(lower_limit)+func(upper_limit)
    area   *= 0.5
    val     = lower_limit
    # calculate the area using the trapezoidal rule
    # enter code:

    calc_tol = 2*tol # just larger than tol to enter the while loop 
    while(calc_tol>tol):
        h *= .5 # half the step size
	# calculate new_area using the trapzoidal rule
	# enter code:
	
        calc_tol = abs(new_area-area)/3 
        area     = new_area # store new values for next iteration
        
    print('Number of intervals = ', (upper_limit-lower_limit)/h )
    return area #while loop ended and we can return the area

prec=1e-8
a=0
b=np.pi
Area = int_adaptive_trapez(f,a,b,prec)
print('Numerical value = ', Area)
print('Error           = ', (2-Area)) # Analytical result is 2
!ec

Hint: To improve the efficiency of the code, you only need to calculate the odd terms in the next estimate of the area, using the algorithm in the compendium:
!bt
\begin{equation}
I_2(a,b)=\frac{1}{2}I_1(a,b)+h_2\sum_{k=\text{odd values}}^{N_2-1}f(a+k h_2)
\end{equation}
!et

* Compare the number of function evaluation for an error of $10^{-8}$ using the algorithm in this exercise and
  the previous for the following integrals:
 * $\int_0^\pi\sin(x)dx$ 
 * $\int_0^1 e^{-x^2}dx$
 * $\int_{-1}^1 x^2dx$


===== Exercise: Adaptive integration - Rombergs algorithm =====
In this exercise we will implement the Romberg algorithm, which is actually closely related to the adaptive trapezoidal rule in the
previous exercise. The algorithm uses the technique from the previous exercise by halving the step size to estimate the error, but an additional trick is used: When we have the error estimate, we can add the error estimate to our numerical estimate of the integral to obtain a higher order accuracy. The algorithm is explained in the compendium and the result is:
!bt
\begin{align}
I&=R_{i,m+1}+\mathcal{O}(h_i^{2m+2})\\
R_{i,m+1}&=R_{i,m}+\frac{1}{4^{m+1}-1}(R_{i+1,m}-R_{i,m}).
\end{align}
!et
Below is a graphical illustration of the algorithm:
FIGURE: [fig-numint/romberg_nb.png, width=800 frac=1.0]

!bc pycod
def int_romberg(func,lower_limit, upper_limit,tol,show=False):
    """ calculates the area of func over the domain lower_limit
        to upper limit for the given tol, if show=True the triangular
        array of intermediate results are printed """
    Nmax = 100
    R      = np.empty([Nmax,Nmax]) # storage buffer
    h      = (upper_limit-lower_limit) # step size
    N      = 1    
    R[0,0] = .5*(func(lower_limit)+func(upper_limit))*h # first estimate   
    for i in range(1,Nmax):
        h /= 2
        N *= 2
	# estimate R[i,0] from the trapezoidal rule:
	# ....
	# next, estimate R[i,1], R[1,2],..,R[1,m+1]:
	#...
	# check tolerance, best guess			
        calc_tol = abs(R[i,i]-R[i-1,i-1])       
        if(calc_tol<tol):
            break  # estimated precision reached, exit for loop


    if(i == Nmax-1):
        print('Romberg routine did not converge after ', Nmax, 'iterations!')
    else:      
        print('Number of intervals = ', N)

    if(show==True):
    # print out the triangular matrix
    # R[0,0]
    # R[1,0] R[1,1]
    # R[2,0] R[2,1] R[2,2]
    # etc. 
  
    return R[i,i] #return the best estimate
!ec

You can check your implementation by comparing with the implementation in SciPy, "Romberg":"https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.romberg.html":
!bc pycod
from scipy import integrate
integrate.romberg(f, a, b, show=True)
!ec

o Compare the adaptive trapezoidal rule and the Romberg algorithm for $\int_{-1}^{1}x^4dx$. Notice the extreme improvement by the Romberg algorithm.


===== Exercise: Evaluate $\int_{a}^{b}x^nf(x) xdx$ =====
We will now look closer at an integral where the derivative has a singularity in the integration domain. We will consider the integral:
!bt
\begin{equation}
\int_0^1 x^{1/2}\cos x dx\simeq  0.53120268
label{eq:numint:i1}
\end{equation}
!et

* Compare the adaptive trapezoidal rule and the Romberg algorithm. Note that in this case the trapezoidal rule does a better job (!). If you compare with the SciPy implementation you will also observe that an error is given because the accuracy is not reached.

Do the following substitution: $\tau=x^2$, and show that the integral can be rewritten as:
!bt
\begin{equation}
2\int_0^1 \tau^{2}\cos\tau^2 d\tau.
label{eq:numint:i2}
\end{equation}
!et

* Estimate the integral once more with the adaptive trapezoidal and Romberg algorithm. Note the greatly improvement in performance for the Romberg method

!bnotice
*It always wise to test out different methods, even if we expect that a specific method is supposed to be better it is not always so. Change of integration variable can greatly improve the performance.*
!enotice

===== Exercise: Gaussian evaluation of $\int_{a}^{b}x^nf(x) xdx$ =====
Gaussian integration is extremely powerful, and should always be considered if speed is an issue. As explained in the compendium the idea behind the Gaussian integration is to approximate the function to be integrated on the domain as a 
polynomial of as *large a degree as possible*, then the numerical integral of this polynomial will be very close to the integral of the function we are seeking. In this case, considering equation (ref{eq:numint:i1}), we can develop similar integration rules as in the compendium, and we choose $ f(x)=1,\,x,\,x^2\,x^3$ to be integrated exact: 
!bt
\begin{align}
\int_{0}^{1}x^{1/2}\,dx&=\frac{2}{3}=\omega_0+\omega_1\,,\\
\int_{0}^{1}x^{1/2+1}\,dx&=\frac{2}{5}=\omega_0x_0+\omega_1x_1\,,\\
\int_{0}^{1}x^{1/2+2}\,dx&=\frac{2}{7}=\omega_0x_0^2+\omega_1x_1^2\,,\\
\int_{0}^{1}x^{1/2+3}\,dx&=\frac{2}{9}=\omega_0x_0^3+\omega_1x_1^3\,,
\end{align}
!et
It is a bit cumbersome to solve the above equations, but in Python it can be done by e.g. using SymPy:
!bc pycod
import sympy as sym
import numpy as np
x1,x2,w1,w2=sym.symbols('x1, x2, w1, w2')
#n=1/2 gives numerical value
n  = sym.Rational(1,2) # gives analytical result
f1 = sym.Eq(w1+w2,1/(n+1))
f2 = sym.Eq(w1*x1+w2*x2,1/(n+2))
f3 = sym.Eq( ... enter missing equation)
f4 = sym.Eq( ... enter missing equation)
sol=sym.solve(... correct syntax ...)
!ec
!bans
!bc pycod
import sympy as sym
import numpy as np
x1,x2,w1,w2=sym.symbols('x1, x2, w1, w2')
#n=1/2 gives numerical value
n = sym.Rational(1,2) # gives analytical result
f1=sym.Eq(w1+w2,1/(n+1))
f2=sym.Eq(w1*x1+w2*x2,1/(n+2))
f3=sym.Eq(w1*x1**2+w2*x2**2,1/(n+3))
f4=sym.Eq(w1*x1**3+w2*x2**3,1/(n+4))
sol=sym.solve([f1,f2,f3,f4],(x1,x2,w1,w2))
print(sol)
!ec
!eans
o Find $x_1$ and $x_2$ and the corresponding weights $\omega_0$ and $\omega_1$
o Implement the Gaussian integration rule in this case and estimate $\int_{a}^{b}x^{1/2}\cos xdx$ 

A correct implementation should give you $I\simeq0.60749779509$, or an accuracy of $10^{-4}$. 
