<!--
File automatically generated using DocOnce (https://github.com/doconce/doconce/):
doconce format html main_taylor.do.txt CHAPTER=document BOOK=document APPENDIX=document --html_style=bootswatch_readable --html_output=taylor-readable --html_code_style=inherit
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="A basic ingredient in modeling: gradients">
<meta name="keywords" content="numerical error,Taylor polynomial,truncation error,Taylor polynomial, error term,Maclaurin series,forward difference,backward difference,central difference,central difference,roundoff erros,machine precision,IEEE 754-1985 standard,roundoff errors">
<title>A basic ingredient in modeling: gradients</title>
<!-- Bootstrap style: bootswatch_readable -->
<!-- doconce format html main_taylor.do.txt CHAPTER=document BOOK=document APPENDIX=document --html_style=bootswatch_readable --html_output=taylor-readable --html_code_style=inherit -->
<link href="https://netdna.bootstrapcdn.com/bootswatch/3.1.1/readable/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->
<style type="text/css">
/* Let inline verbatim have the same color as the surroundings */
code { color: inherit; background-color: transparent; }
/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:64px;      /* fixed header height for style bootswatch_readable */
  margin:-64px 0 0; /* negative fixed header height */
}
</style>
</head>

<!-- tocinfo
{'highest level': 1,
 'sections': [('Table of contents',
               1,
               'table_of_contents',
               'table_of_contents'),
              ('Why are gradients important?',
               1,
               None,
               'why-are-gradients-important'),
              ('Continuous functions and finite representation: numerical '
               'errors',
               1,
               None,
               'continuous-functions-and-finite-representation-numerical-errors'),
              ('Taylor polynomial approximation',
               1,
               None,
               'taylor-polynomial-approximation'),
              ('Calculating Numerical Derivatives of Functions',
               1,
               None,
               'calculating-numerical-derivatives-of-functions'),
              ('Higher order derivative',
               3,
               'sec:taylor:hhd',
               'sec:taylor:hhd'),
              ('Roundoff Errors', 2, None, 'roundoff-errors'),
              ('Binary numbers', 1, None, 'binary-numbers'),
              ('Floating point numbers and the IEEE 754-1985 standard',
               2,
               None,
               'floating-point-numbers-and-the-ieee-754-1985-standard'),
              ('Roundoff error and truncation error in numerical derivatives',
               3,
               None,
               'roundoff-error-and-truncation-error-in-numerical-derivatives'),
              ('Bibliography', 1, None, 'bibliography')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<!-- newcommands_keep.tex -->
$$
\newcommand{\no}{\nonumber}
$$



<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="aylor-readable.html">A basic ingredient in modeling: gradients</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="#table_of_contents" style="font-size: 80%;"><b>Table of contents</b></a></li>
     <!-- navigation toc: --> <li><a href="#why-are-gradients-important" style="font-size: 80%;"><b>Why are gradients important?</b></a></li>
     <!-- navigation toc: --> <li><a href="#continuous-functions-and-finite-representation-numerical-errors" style="font-size: 80%;"><b>Continuous functions and finite representation: numerical errors</b></a></li>
     <!-- navigation toc: --> <li><a href="#taylor-polynomial-approximation" style="font-size: 80%;"><b>Taylor polynomial approximation</b></a></li>
     <!-- navigation toc: --> <li><a href="#calculating-numerical-derivatives-of-functions" style="font-size: 80%;"><b>Calculating Numerical Derivatives of Functions</b></a></li>
     <!-- navigation toc: --> <li><a href="#sec:taylor:hhd" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Higher order derivative</a></li>
     <!-- navigation toc: --> <li><a href="._taylor-readable001.html#roundoff-errors" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Roundoff Errors</a></li>
     <!-- navigation toc: --> <li><a href="._taylor-readable002.html#binary-numbers" style="font-size: 80%;"><b>Binary numbers</b></a></li>
     <!-- navigation toc: --> <li><a href="._taylor-readable003.html#floating-point-numbers-and-the-ieee-754-1985-standard" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Floating point numbers and the IEEE 754-1985 standard</a></li>
     <!-- navigation toc: --> <li><a href="._taylor-readable003.html#roundoff-error-and-truncation-error-in-numerical-derivatives" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Roundoff error and truncation error in numerical derivatives</a></li>
     <!-- navigation toc: --> <li><a href="._taylor-readable003.html#bibliography" style="font-size: 80%;"><b>Bibliography</b></a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->
<div class="container">
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->
<a name="part0000"></a>
<!-- ------------------- main content ---------------------- -->
<div class="jumbotron">
<center>
<h1>A basic ingredient in modeling: gradients</h1>
</center>  <!-- document title -->

<!-- author(s): Aksel Hiorth -->
<center>
<b>Aksel Hiorth</b> 
</center>
<!-- institution(s) -->
<br>
<p>University of Stavanger
<center>
<h4>Aug 26, 2024</h4>
</center> <!-- date -->
<br>
</p>


</div> <!-- end jumbotron -->
<h1 id="table_of_contents">Table of contents</h1>

<div class='toc'>
<p><a href="#why-are-gradients-important"> Why are gradients important? </a></p>
<p><a href="#continuous-functions-and-finite-representation-numerical-errors"> Continuous functions and finite representation: numerical errors </a></p>
<p><a href="#taylor-polynomial-approximation"> Taylor polynomial approximation </a></p>
<p><a href="#calculating-numerical-derivatives-of-functions"> Calculating Numerical Derivatives of Functions </a></p>
<p><span class="tab"> <a href="._taylor-readable001.html#roundoff-errors"> Roundoff Errors </a></p>
<p><a href="._taylor-readable002.html#binary-numbers"> Binary numbers  </a></p>
<p><span class="tab"> <a href="._taylor-readable003.html#floating-point-numbers-and-the-ieee-754-1985-standard"> Floating point numbers and the IEEE 754-1985 standard </a></p>
<p><a href="._taylor-readable003.html#bibliography"> Bibliography </a></p>
</div>
<br>

<!-- Common Mako variables and functions -->
<h1 id="why-are-gradients-important" class="anchor">Why are gradients important? </h1>
<p>If you are going to walk up a mountain, it is not enough to know the height of the mountain, you also want to know how steep the mountain is. Even if the mountain is low, it can still be difficult to reach the top if it is very steep. The steepness is how much the height changes as function of time (if we walk at the same pace) or how much the height changes with horizontal distance. To be more precise, let's say we move from \( x_a \) to \( x_b \), and the height increases from \( h_a \) to \( h_b \), the steepness is</p>
$$
\begin{equation}
\frac{h_b-h_a}{x_b-x_a}.
\tag{1}
\end{equation}
$$

<p>If we climb a ladder, the horizontal movement is small (\( x_b-x_a \) is small) and the increase in height is large, hence the steepness is large. If we walk a long a flat path we have no vertical movement and the steepness is zero (\( h_a=h_b \)). Mathematically, if we let \( x_b \) and \( x_a \) be infinitely close, the steepness is called a <em>gradient</em>, and we denote it by \( \nabla h(x) \). Note also that the sign of the gradient tells something about the direction. If we climb up a ladder the height is increasing (\( h_a < h_b \)) and the gradient is positive, on the other hand if we are climbing down the height is decreasing (\( h_a>h_b \)) and the gradient is negative. </p>

<p>If we consider the height of a mountain in two dimensions, \( h=h(x,y) \), the height is represented by the contour lines on a map. The spacing between the contour lines is the gradient, if the spacing between the contour lines is small the mountain side is steeper than if the spacing is larger.  </p>

<div class="alert alert-block alert-success alert-text-normal"><b>Gradients vs derivatives</b>
<p>If we are only considering a single variable, height as a function of time or position, \( x \), we often denote the gradient (\( \nabla h \)), \( h^\prime(x) \) and call it the derivative of \( h(x) \). In higher dimensions, e.g. \( h(x,y) \), we use the term partial derivatives, because there are now two different variables we can vary e.g. latitude and longitude. The gradient is now a <em>vector</em>, \( \nabla=[\partial h/\partial x, \partial h/\partial y] \). \( \partial h/\partial x \) is the partial derivative of \( h(x,y) \) with respect to \( x \), i.e. we keep \( y \) constant and only differentiate with respect to \( x \).   </p>
</div>


<p>Another example where gradients are important is the flow of heat. Heat flows from hot to cold places, and the amount of heat is proportional to the temperature difference, i.e. a gradient in temperature. The flow of air is also from points of high pressure to low pressure, i.e. a gradient in pressure. </p>

<p>A primary task of a modeler is to predict something. If there are no gradients in a system, nothing will happen and there is no reason to model anything. Hence, an extremely important task when we model something is to analyze gradients carefully. If gradients are not represented correctly, the output of the simulation will introduce errors that can be so large that one cannot trust the results.</p>
<h1 id="continuous-functions-and-finite-representation-numerical-errors" class="anchor">Continuous functions and finite representation: numerical errors </h1>
<p>A computer can only deal with numbers. To simulate a physical system in a computer we have to divide space and time into finite pieces, and assign numbers to different parts of time and/or space. </p>

<div class="alert alert-block alert-success alert-text-normal"><b>Numerical errors</b>
<p>Whenever we divide space and/or time into finite pieces, we introduce numerical errors. These errors tend to become smaller, but not always, when we use more pieces. The difference between the "true" answer and the answer obtained from a practical (numerical) calculation is called the <em>numerical error</em>.</p>
</div>


<p>When we divide space and time into finite pieces to represent them in a computer, a natural question is how many pieces do we need? Consider an almost trivial example, let say you want to visualize the function \( f(x)=\sin x \). To do this we need to choose where, which values of \( x \), we want to evaluate our function. To make an efficient program, we want to use as few points as possible but still capture the shape of the function.  
In figure <a href="#fig:taylor:sinx">1</a>, we have plotted \( \sin x \) for various discretization steps (\( \Delta x \), spacing between the points) in the interval \( [-\pi,\pi] \).
</p>

<center> <!-- figure label: --> <div id="fig:taylor:sinx"></div> <!-- FIGURE -->
<hr class="figure">
<center>
<p class="caption">Figure 1: A plot of \( \sin x \) for different spacing (\( \Delta x \)) of the \( x \)-values.  <!-- caption label: fig:taylor:sinx --></p>
</center>
<p><img src="fig-taylor/func_plot.png" width="600" align="bottom"></p>
</center>

<p>From the figure we see that in some areas only a couple of points are needed in order to
represent the function well, and in some areas more points are needed. To state it more clearly; between \( [-1,1] \) a linear function (few points) approximate \( \sin x \) well, 
whereas in the area where the gradient of the function changes more rapidly e.g. between \( [-2,-1] \), we need the points to be more closely spaced to capture the behavior of the function.
</p>

<p>What is a <em>good representation</em> of the function? We cannot rely on visual inspection every time, and most of the time we do not know the answer, so we would not know what to compare with. In the next section, we will show how the Taylor polynomial representation of a function is a natural starting point to answer this question.</p>
<h1 id="taylor-polynomial-approximation" class="anchor">Taylor polynomial approximation </h1>
<p>How can we evaluate numerical errors if we do not know the true answer? There are at least two answers to this:</p>

<ol>
<li> The pragmatic engineering approach is to do a simulation with a coarse grid, then refine the grid until the solution does not change much. This is perfectly fine <em>if you know that the numerical code is bug free</em>, because even if the simulation converges to a solution, we do not know if it is the <em>true solution</em>. In many cases this is not so. Therefore, even in well tested industrial codes, it is always good to test them on a simple test case where you know the exact solution.</li>
<li> Taylor's formula can be used to represent any continuous function with continuous gradients or most solutions to a mathematical model. Taylor's formula gives us an estimate of the numerical error introduced when we divide space and time into finite pieces.</li>
</ol>
<p>There are many ways of representing a function, \( f(x) \), like Fourier series and Legendre polynomials, but perhaps one of the most widely used is Taylor polynomials.   
Taylor series are perfect for computers, simply because they make possible to evaluate any function with a set of simple operations: <em>addition, subtraction, and multiplication</em>. Let us start off with the formal definition: 
</p>
<div class="alert alert-block alert-success alert-text-normal"><b>Taylor polynomial:</b>
<p>The Taylor polynomial, \( P_n(x) \) of degree \( n \) of a function \( f(x) \) at the point \( c \) is defined as:</p>
$$
\begin{align}
 P_n(x) &= f(c)+f^\prime(c)(x-c)+\frac{f^{\prime\prime}(c)}{2!}(x-c)^2+\cdots+\frac{f^{(n)}(c)}{n!}(x-c)^n\nonumber\\ 
&=\sum_{k=0}^n\frac{f^{(k)}(c)}{k!}(x-c)^k.\tag{2}
\end{align}
$$
</div>

<p>Note that \( x \) can be anything, space, time, temperature, etc. If the series is around the point \( c=0 \), the Taylor polynomial \( P_n(x) \) is often called a Maclaurin polynomial. If the series converge (i.e. the higher order terms approach zero), then we can represent the function \( f(x) \) with its corresponding Taylor series around the point \( x=c \):</p>
$$
\begin{align}
 f(x) &= f(c)+f^\prime(c)(x-c)+\frac{f^{\prime\prime}(c)}{2!}(x-c)^2+\cdots
=\sum_{k=0}^\infty\frac{f^{(k)}}{k!}(x-c)^k.\tag{3}
\end{align}
$$

<div class="alert alert-block alert-success alert-text-normal"><b>The magic of Taylors formula</b>
<p>Taylors formula, equation <a href="#mjx-eqn-3">(3)</a>, states that if we know the function value and its gradients <em>at a single point \( c \)</em>, we can estimate the function everywhere <em>using only  information from the single point \( c \)</em>. How can information from a single point be used to predict the behavior of the function everywhere? One way of thinking about this is to imagine an object moving in a constant gravitational field without air resistance. Newtons laws tell us that  if we know the starting point e.g. (\( x(0) \)), the velocity (\( v=dx/dt \)), and the acceleration (\( a=dv/dt=d^2x/dt^2 \)) in that point we can predict the trajectory of the object. This trajectory is exactly the first terms in Taylor's formula, \( x(t)=x(0) + vt+at^2/2 \). </p>
</div>

<p>An example of how Taylors formula works for a known function, can be seen in figure <a href="#fig:mac_sin">2</a>, where we show the first nine terms in the Maclaurin series for \( \sin x \) (all even terms are zero). </p>

<center> <!-- figure label: --> <div id="fig:mac_sin"></div> <!-- FIGURE -->
<hr class="figure">
<center>
<p class="caption">Figure 2: Nine first terms of the Maclaurin series of \( \sin x \).  <!-- caption label: fig:mac_sin --></p>
</center>
<p><img src="fig-taylor/mac_sin.png" width="600" align="bottom"></p>
</center>

<p>Notice that close to \( x=0 \) we only need one term, as we move further away from this point more and more terms need to be added. Thus, Taylors formula is only exact if we include an infinite number of terms. In practice, we only include a limited number of terms and truncate the series up to a given order. Luckily, Taylors formula include an estimate of the error we have when we truncate the series. </p>
<div class="alert alert-block alert-success alert-text-normal"><b>Truncation error in Taylors formula:</b>
$$
\begin{align}
R_n(x)&=f(x)-P_n(x)=\frac{f^{(n+1)}(\eta)}{(n+1)!}(x-c)^{n+1}\nonumber\\ 
      &=\frac{1}{n!}\int_c^x(x-\tau)^{n}f^{(n+1)}(\tau)d\tau,\tag{4}
\end{align}
$$

<p>Notice that the mathematical formula is basically the next order term (\( n+1 \)) in the Taylor series, but with \( f^{(n+1)}(c)\to f^{(n+1)}(\eta) \). \( \eta \) is an (unknown) value in the domain \( [x,c] \).</p>
</div>

<p>Notice that if \( c \) is very far from \( x \) the truncation error increases. The fact that we do not know the value of \( \eta \) is usually not a problem, in many cases we just replace \( f(\eta) \) with the maximum value it can take on the domain. Equation <a href="#mjx-eqn-4">(4)</a> gives us an direct estimate of discretization error. </p>
<div class="alert alert-block alert-success alert-text-normal"><b>Example: evaluate \( \sin x \)</b>
<p>Whenever you do e.g. <code>np.sin(1)</code> in Python or an equivalent statement in another language, Python has to tell the computer how to evaluate \( \sin x \) at \( x=1 \). Write a Python code that calculates \( \sin x \) up to a user specified accuracy.</p>

<p>
<b>Solution</b>
The Maclaurin series of \( \sin x \) is:
</p>
$$
\begin{equation}
\sin x = x-\frac{x^3}{3!}+\frac{x^5}{5!}-\frac{x^7}{7!}+\cdots=\sum_{k=0}^{\infty}\frac{(-1)^n}{(2n+1)!}x^{2n+1}.
\tag{5}
\end{equation}
$$

<p>If we want to calculate \( \sin x \) to a precision lower than a specified value we can do it as follows:</p>


<!-- code=python (!bc pypro) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #ffffff">
  <pre style="line-height: 125%;"><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>

<span style="color: #3D7B7B; font-style: italic"># Sinus implementation using the Maclaurin Serie</span>
<span style="color: #3D7B7B; font-style: italic"># By setting a value for eps this value will be used</span>
<span style="color: #3D7B7B; font-style: italic"># if not provided</span>
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">my_sin</span>(x,eps<span style="color: #666666">=1e-16</span>):
    f <span style="color: #666666">=</span> power <span style="color: #666666">=</span> x
    x2 <span style="color: #666666">=</span> x<span style="color: #666666">*</span>x
    sign <span style="color: #666666">=</span> <span style="color: #666666">1</span>
    i<span style="color: #666666">=0</span>
    <span style="color: #008000; font-weight: bold">while</span>(power<span style="color: #666666">&gt;=</span>eps):
        sign <span style="color: #666666">=</span> <span style="color: #666666">-</span> sign
        power <span style="color: #666666">*=</span> x2<span style="color: #666666">/</span>(<span style="color: #666666">2*</span>i<span style="color: #666666">+2</span>)<span style="color: #666666">/</span>(<span style="color: #666666">2*</span>i<span style="color: #666666">+3</span>)
        f <span style="color: #666666">+=</span> sign<span style="color: #666666">*</span>power
        i <span style="color: #666666">+=</span> <span style="color: #666666">1</span>
    <span style="color: #008000">print</span>(<span style="color: #BA2121">&#39;No function evaluations: &#39;</span>, i)
    <span style="color: #008000; font-weight: bold">return</span> f

x<span style="color: #666666">=0.8</span>
eps <span style="color: #666666">=</span> <span style="color: #666666">1e-9</span>
<span style="color: #008000">print</span>(my_sin(x,eps), <span style="color: #BA2121">&#39;error = &#39;</span>, np<span style="color: #666666">.</span>sin(x)<span style="color: #666666">-</span>my_sin(x,eps))
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>

<p>This implementation needs some explanation:</p>

<ul>
<li> The error term is given in equation <a href="#mjx-eqn-4">(4)</a>, and it is an even power in \( x \). We do not know which \( \eta \) to use in equation <a href="#mjx-eqn-4">(4)</a>, instead we simply say that the error in our estimate is smaller than the highest order term. Thus, we stop the evaluation if the highest order term in the series is lower than the uncertainty. Note that the final error has to be smaller as the higher order terms in any convergent series are smaller than the previous.  Our estimate should then always be better than the specified accuracy.</li>
<li> We evaluate the polynomials in the Taylor series by using the previous values to avoid too many multiplications within the loop, we do this by using the following identity:</li>
</ul>
$$
  \begin{align}
  \sin x&=\sum_{k=0}^{\infty} (-1)^nt_n, \text{ where: } t_n\equiv\frac{x^{2n+1}}{(2n+1)!}, \text{ hence :}\nonumber\\ 
  t_{n+1}&=\frac{x^{2(n+1)+1}}{(2(n+1)+1)!}=\frac{x^{2n+1}x^2}{(2n+1)! (2n+2)(2n+3)}\nonumber\\ 
  &=t_n\frac{x^2}{(2n+2)(2n+3)}
\tag{6}
\end{align}
$$
</div>

<h1 id="calculating-numerical-derivatives-of-functions" class="anchor">Calculating Numerical Derivatives of Functions </h1>

<p>As stated earlier many models are described by differential equations. Differential equations contain derivatives, and we need to tell the computer how to calculate these. By using a simple transformation, \( x\to x+h \) and \( c\to x \) (hence \( x-c\to h \)), Taylors formula in equation <a href="#mjx-eqn-3">(3)</a> can be written as:</p>
$$
\begin{equation}
f(x+h)=f(x)+f^\prime(x)h+\frac{1}{2}f^{\prime\prime}(x)h^2+\cdots.
\tag{7}
\end{equation}
$$

<p>This is useful because this equation contains the derivative of \( f(x) \) on the right hand side. To be even more explicit let's truncate the series to a certain power. Remember that you can always do this but we need to replace \( x \) with \( \eta \) in the last term we choose to keep</p>
$$
\begin{equation}
f(x+h)=f(x)+f^\prime(x)h+\frac{1}{2}f^{\prime\prime}(\eta)h^2
\tag{8}
\end{equation}
$$

<p>where \( \eta\in[x,x+h] \). Solving this equation with respect to \( f^\prime(x) \) gives:</p>
$$
\begin{equation}
f^\prime(x)=\frac{f(x+h)-f(x)}{h}-\frac{1}{2}f^{\prime\prime}(\eta)h.
\tag{9}
\end{equation}
$$

<p>Note that if \( h\to0 \), this expression is equal to the definition of the derivative. The beauty of equation <a href="#mjx-eqn-9">(9)</a> is that it contains an expression for the error <em>when \( h \) is not zero</em>. Equation <a href="#mjx-eqn-9">(9)</a> is usually called the <em>forward difference</em> . As you might guess, we can also choose to use the <em>backward difference</em>  by simply replacing \( h\to-h \). Is equation <a href="#mjx-eqn-9">(9)</a> the only formula for the derivative? The answer is no, and we are going to derive the formula for the <em>central difference</em> , by writing Taylors formula for \( x+h \) and \( x-h \) up to the third order:</p>

$$
\begin{align}
f(x+h)&=f(x)+f^\prime(x)h+\frac{1}{2}f^{\prime\prime}(x)h^2+\frac{1}{3!}f^{(3)}(\eta_1)h^3,   
\tag{10}\\ 
f(x-h)&=f(x)-f^\prime(x)h+\frac{1}{2}f^{\prime\prime}(x)h^2-\frac{1}{3!}f^{(3)}(\eta_2)h^3.
\tag{11}
\end{align}
$$

<p>where \( \eta_1\in[x,x+h] \), and \( \eta_2\in[x-h,x] \). Subtracting  equation <a href="#mjx-eqn-10">(10)</a> and <a href="#mjx-eqn-11">(11)</a>, we get the following expression for the central difference: </p>
$$
\begin{equation}
f^\prime(x)=\frac{f(x+h)-f(x-h)}{2h} -\frac{h^2}{6}f^{(3)}(\eta),label{eq:taylor:cd}
\end{equation}
$$

<p>where \( \eta\in[x-h,x+h] \). Note that the error term in this equation is <em>one order higher</em> than in equation <a href="#mjx-eqn-9">(9)</a>, meaning that it is expected to be more accurate. Figure <a href="#fig:taylor:fd">3</a> is a graphical representation of the finite difference approximations to the derivative. </p>

<center> <!-- figure label: --> <div id="fig:taylor:fd"></div> <!-- FIGURE -->
<hr class="figure">
<center>
<p class="caption">Figure 3: A graphical interpretation of the forward and central difference formula.  <!-- caption label: fig:taylor:fd --></p>
</center>
<p><img src="fig-taylor/fd.png" width="400" align="bottom"></p>
</center>

<h3 id="sec:taylor:hhd" class="anchor">Higher order derivative</h3>
<p>We are now in the position to derive a formula for the second order derivative. Instead of subtracting equation <a href="#mjx-eqn-10">(10)</a> and <a href="#mjx-eqn-11">(11)</a>, we can add them. Then the first order derivative disappear and we are left with an expression for the second derivative:</p>
$$
\begin{equation}
f^{\prime\prime}(x) = \frac{f(x+h)+f(x-h)-2f(x)}{h^2}- \frac{h^2}{12}f^{(4)}(\eta)
\tag{12},
\end{equation}
$$

<p>We can also calculate higher order derivatives by expanding about \( x\pm h \) and \( x\pm 2h \), adding one more term it follows from equation \eqref{eq:taylor:cd}:</p>
$$
\begin{align}
f(x+h)-f(x-h)&=2hf^\prime(x)+\frac{2}{3!}h^3f^{(3)}(x)+\frac{2}{5!}h^5f^{(5)}(\eta),\no
\tag{13}\\ 
f(x+2h)-f(x-2h)&=2(2h)f^\prime(x)+\frac{2}{3!}(2h)^3f^{(3)}(x)+\frac{2}{5!}h^5f^{(5)}(\eta).
\label{}
\end{align}
$$

<p>It is now possible to find an expression for the third derivative:</p>
$$
\begin{equation}
f^{(3)}(x) = \frac{f(x-h)-f(x+h)-\frac{1}{2}f(x-2h)+\frac{1}{2}f(x+2h)}{h^3}+ \frac{h^2}{4}f^{(5)}(\eta)
\tag{14},
\end{equation}
$$

<p>or a higher order first derivative:</p>
$$
\begin{equation}
f^{\prime}(x) = \frac{2f(x+h)-2f(x-h)-\frac{1}{4}f(x+2h)+\frac{1}{4}f(x-2h)}{3h}+ \frac{h^4}{30}f^{(5)}(\eta)
\tag{15}.
\end{equation}
$$


<div class="alert alert-block alert-success alert-text-normal"><b>Example: calculate the numerical derivative and second derivative of \( \sin x \)</b>
<p>Choose a specific point, e.g. \( x=1 \), and calculate the numerical error for various values of the step size \( h \).</p>
<p>
<b>Solution:</b>
The derivative of \( \sin x \) is \( \cos x \), we can calculate the numerical derivatives using Python
</p>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #ffffff">
  <pre style="line-height: 125%;"><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">f</span>(x):
    <span style="color: #008000; font-weight: bold">return</span> np<span style="color: #666666">.</span>sin(x)
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">fd</span>(f,x,h):
<span style="color: #bbbbbb">    </span><span style="color: #BA2121; font-style: italic">&quot;&quot;&quot; f&#39;(x) forward difference &quot;&quot;&quot;</span>
    <span style="color: #008000; font-weight: bold">return</span> (f(x<span style="color: #666666">+</span>h)<span style="color: #666666">-</span>f(x))<span style="color: #666666">/</span>h

<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">fc</span>(f,x,h):
<span style="color: #bbbbbb">    </span><span style="color: #BA2121; font-style: italic">&quot;&quot;&quot; f&#39;(x) central difference &quot;&quot;&quot;</span>
    <span style="color: #008000; font-weight: bold">return</span> <span style="color: #666666">0.5*</span>(f(x<span style="color: #666666">+</span>h)<span style="color: #666666">-</span>f(x<span style="color: #666666">-</span>h))<span style="color: #666666">/</span>h

<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">fdd</span>(f,x,h):
<span style="color: #bbbbbb">    </span><span style="color: #BA2121; font-style: italic">&quot;&quot;&quot; f&#39;&#39;(x) second order derivative &quot;&quot;&quot;</span>
    <span style="color: #008000; font-weight: bold">return</span> (f(x<span style="color: #666666">+</span>h)<span style="color: #666666">+</span>f(x<span style="color: #666666">-</span>h)<span style="color: #666666">-2*</span>f(x))<span style="color: #666666">/</span>(h<span style="color: #666666">*</span>h)

<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">fd3</span>(f,x,h):
<span style="color: #bbbbbb">    </span><span style="color: #BA2121; font-style: italic">&quot;&quot;&quot; f&#39;&#39;&#39;(x) third order derivative &quot;&quot;&quot;</span>
    <span style="color: #008000; font-weight: bold">return</span> (<span style="color: #666666">2*</span>f(x<span style="color: #666666">-</span>h)<span style="color: #666666">-2*</span>f(x<span style="color: #666666">+</span>h)<span style="color: #666666">-</span>f(x<span style="color: #666666">-2*</span>h)<span style="color: #666666">+</span>f(x<span style="color: #666666">+2*</span>h))<span style="color: #666666">/</span>(<span style="color: #666666">2*</span>h<span style="color: #666666">*</span>h<span style="color: #666666">*</span>h)

<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">fd_4</span>(f,x,h):
<span style="color: #bbbbbb">    </span><span style="color: #BA2121; font-style: italic">&quot;&quot;&quot; f&#39;(x) fourth order &quot;&quot;&quot;</span>
    <span style="color: #008000; font-weight: bold">return</span> (<span style="color: #666666">8*</span>f(x<span style="color: #666666">+</span>h)<span style="color: #666666">-8*</span>f(x<span style="color: #666666">-</span>h)<span style="color: #666666">-</span>f(x<span style="color: #666666">+2*</span>h)<span style="color: #666666">+</span>f(x<span style="color: #666666">-2*</span>h))<span style="color: #666666">/</span>(<span style="color: #666666">12*</span>h)
x<span style="color: #666666">=1</span>
h<span style="color: #666666">=</span>np<span style="color: #666666">.</span>logspace(<span style="color: #666666">-15</span>,<span style="color: #666666">0.1</span>,<span style="color: #666666">10</span>)
plt<span style="color: #666666">.</span>plot(h,np<span style="color: #666666">.</span>abs(np<span style="color: #666666">.</span>cos(x)<span style="color: #666666">-</span>fd(f,x,h)), <span style="color: #BA2121">&#39;-o&#39;</span>,label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;forward difference&#39;</span>)
plt<span style="color: #666666">.</span>plot(h,np<span style="color: #666666">.</span>abs(np<span style="color: #666666">.</span>cos(x)<span style="color: #666666">-</span>fc(f,x,h)),<span style="color: #BA2121">&#39;-x&#39;</span>, label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;central difference&#39;</span>)
plt<span style="color: #666666">.</span>plot(h,np<span style="color: #666666">.</span>abs(np<span style="color: #666666">.</span>cos(x)<span style="color: #666666">-</span>fd_4(f,x,h)),<span style="color: #BA2121">&#39;-*&#39;</span>,label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;derivative - fourth order&#39;</span>)
plt<span style="color: #666666">.</span>plot(h,np<span style="color: #666666">.</span>abs(<span style="color: #666666">-</span>np<span style="color: #666666">.</span>sin(x)<span style="color: #666666">-</span>fdd(f,x,h)),<span style="color: #BA2121">&#39;-*&#39;</span>,label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;second derivative&#39;</span>)
h<span style="color: #666666">=</span>np<span style="color: #666666">.</span>logspace(<span style="color: #666666">-7</span>,<span style="color: #666666">0.1</span>,<span style="color: #666666">10</span>)
plt<span style="color: #666666">.</span>plot(h,np<span style="color: #666666">.</span>abs(<span style="color: #666666">-</span>np<span style="color: #666666">.</span>cos(x)<span style="color: #666666">-</span>fd3(f,x,h)),<span style="color: #BA2121">&#39;-*&#39;</span>,label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;third derivative&#39;</span>)

plt<span style="color: #666666">.</span>grid()
plt<span style="color: #666666">.</span>legend()
plt<span style="color: #666666">.</span>xscale(<span style="color: #BA2121">&#39;log&#39;</span>)
plt<span style="color: #666666">.</span>yscale(<span style="color: #BA2121">&#39;log&#39;</span>)
plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">&#39;Step size $h$&#39;</span>)
plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">&#39;Numerical error&#39;</span>)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>

<p>Figure <a href="#fig:taylor:df2">4</a> shows the result of the code above.</p>
</div>


<center> <!-- figure label: --> <div id="fig:taylor:df2"></div> <!-- FIGURE -->
<hr class="figure">
<center>
<p class="caption">Figure 4: Numerical error of derivatives of \( \sin x \) for various step sizes.  <!-- caption label: fig:taylor:df2 --></p>
</center>
<p><img src="fig-taylor/df2_mod.png" width="400" align="bottom"></p>
</center>

<p>There are several important lessons from figure <a href="#fig:taylor:df2">4</a>:</p>
<ol>
<li> When the step size is high and decreasing (from right to left in the figure), we clearly see that the numerical error <em>decreases</em>.</li>
<li> The numerical error scales as expected from right to left. The forward difference formula scales as \( h \), i.e. decreasing the step size by 10 reduces the numerical error by 10. The central difference and second order derivative formula scales as \( h^2 \), reducing the step size by 10 reduces the numerical error by 100</li>
<li> At a certain step size the numerical error starts to <em>increase</em>. For the forward difference formula this happens at \( ~10^{-8} \).</li>
</ol>
<p>The numerical error has a minimum, <em>it does not continue to decrease when \( h \) decreases</em>. The explanation for this behavior are two competing errors: <em>truncation errors</em> and <em>roundoff errors</em>. The truncation errors have already been discussed in great detail, in the next section we will look at roundoff errors.</p>

<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pager">
  <li class="next">
    <a href="._taylor-readable001.html">Next &rarr;</a>
  </li>
</ul>
<!-- ------------------- end of main content --------------- -->
</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->
</body>
</html>

